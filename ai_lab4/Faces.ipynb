{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "24d479af",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24d479af",
        "outputId": "83b60944-93ce-46c7-dd72-aae32d687848"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-05-18 17:53:13--  http://www.soshnikov.com/permanent/data/petfaces.tar.gz\n",
            "Resolving www.soshnikov.com (www.soshnikov.com)... 79.137.227.122\n",
            "Connecting to www.soshnikov.com (www.soshnikov.com)|79.137.227.122|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 24483412 (23M) [application/x-tar]\n",
            "Saving to: ‘petfaces.tar.gz’\n",
            "\n",
            "petfaces.tar.gz     100%[===================>]  23.35M   199KB/s    in 2m 6s   \n",
            "\n",
            "2023-05-18 17:55:19 (190 KB/s) - ‘petfaces.tar.gz’ saved [24483412/24483412]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget http://www.soshnikov.com/permanent/data/petfaces.tar.gz\n",
        "!tar xfz petfaces.tar.gz\n",
        "!rm petfaces.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "1a8e0ada",
      "metadata": {
        "id": "1a8e0ada"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "from skimage import io\n",
        "import torch\n",
        "\n",
        "from tqdm import tqdm, tqdm_notebook\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "\n",
        "from torchvision import transforms\n",
        "from multiprocessing.pool import ThreadPool\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "\n",
        "from matplotlib import colors, pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore', category=DeprecationWarning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "3aa0a009",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3aa0a009",
        "outputId": "16845140-3094-4d46-fe3f-9e9d77757b7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "DATA_MODES = ['train', 'val', 'test']\n",
        "RESCALE_SIZE = 224\n",
        "\n",
        "DEVICE = torch.device(\"cuda\")\n",
        "if torch.cuda.is_available:\n",
        "  print(\"cuda\")\n",
        "else: print(\"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Опишем свой класса датасета для работы с изображениями"
      ],
      "metadata": {
        "id": "kR2WFZ_X2Q1B"
      },
      "id": "kR2WFZ_X2Q1B"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "ca086854",
      "metadata": {
        "id": "ca086854"
      },
      "outputs": [],
      "source": [
        "class PetFacesDataset(Dataset):\n",
        "    def __init__(self, files, mode, task=\"bin\"):\n",
        "        super().__init__()\n",
        "        self.files = sorted(files)\n",
        "        self.mode = mode\n",
        "        self.task = task\n",
        "\n",
        "        if self.mode not in DATA_MODES:\n",
        "            print(f\"{self.mode} is not correct; correct modes: {DATA_MODES}\")\n",
        "            raise NameError\n",
        "\n",
        "        self.len_ = len(self.files)\n",
        "     \n",
        "        self.label_encoder = LabelEncoder()\n",
        "\n",
        "        if self.mode != 'test':\n",
        "            if self.task == \"bin\":\n",
        "                self.labels = [path.parent.name[0:3] for path in self.files]\n",
        "                self.label_encoder.fit(self.labels)\n",
        "                with open('label_encoder.pkl', 'wb') as le_dump_file:\n",
        "                    pickle.dump(self.label_encoder, le_dump_file)\n",
        "                \n",
        "            else:\n",
        "                self.labels = [path.parent.name for path in self.files]\n",
        "                self.label_encoder.fit(self.labels)\n",
        "                with open('label_encoder.pkl', 'wb') as le_dump_file:\n",
        "                    pickle.dump(self.label_encoder, le_dump_file)\n",
        "\n",
        "                      \n",
        "    def __len__(self):\n",
        "        return self.len_\n",
        "      \n",
        "    def load_sample(self, file):\n",
        "        image = Image.open(file)\n",
        "        image.load()\n",
        "        return image\n",
        "  \n",
        "    def __getitem__(self, index):\n",
        "        transform = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) \n",
        "        ])\n",
        "        x = self.load_sample(self.files[index])\n",
        "        x = self._prepare_sample(x)\n",
        "        x = np.array(x / 255, dtype='float32')\n",
        "        x = transform(x)\n",
        "        if self.mode == 'test':\n",
        "            return x\n",
        "        else:\n",
        "            label = self.labels[index]\n",
        "            label_id = self.label_encoder.transform([label])\n",
        "            y = label_id.item()\n",
        "            return x, y\n",
        "        \n",
        "    def _prepare_sample(self, image):\n",
        "        image = image.resize((RESCALE_SIZE, RESCALE_SIZE))\n",
        "        return np.array(image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "6d888896",
      "metadata": {
        "id": "6d888896"
      },
      "outputs": [],
      "source": [
        "DIR = Path('petfaces')\n",
        "task = \"bin\"\n",
        "files = sorted(list(DIR.rglob('*.jpg')))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Разделяем данные на тестовые и тренировочные, выбирая в качестве меток 3 символа названия папок(они соответствуют \"cat\" и \"dog\", то есть задаче бинарной классификации)"
      ],
      "metadata": {
        "id": "1InOrgbU2d8l"
      },
      "id": "1InOrgbU2d8l"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "83c74294",
      "metadata": {
        "id": "83c74294"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "y = [path.parent.name[0:3] for path in files]\n",
        "\n",
        "train_data, test_data = train_test_split(files, train_size=0.8, stratify=y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "9428d4d6",
      "metadata": {
        "id": "9428d4d6"
      },
      "outputs": [],
      "source": [
        "train_dataset = PetFacesDataset(train_data, \"train\")\n",
        "test_dataset = PetFacesDataset(test_data, \"val\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Опишем нейросеть, перечислением её слоёв"
      ],
      "metadata": {
        "id": "ska9L5EU2tXv"
      },
      "id": "ska9L5EU2tXv"
    },
    {
      "cell_type": "code",
      "source": [
        "class NetWork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(NetWork, self).__init__()\n",
        "    self.batch1 = nn.BatchNorm2d(3)\n",
        "    self.conv1 = nn.Conv2d(3, 6, 3)\n",
        "    self.pool1 = nn.MaxPool2d(kernel_size=4)\n",
        "    self.batch2 = nn.BatchNorm2d(6)\n",
        "    self.conv2 = nn.Conv2d(6, 12, 3)\n",
        "    self.pool2 = nn.MaxPool2d(kernel_size=4)\n",
        "    self.batch3 = nn.BatchNorm2d(12)\n",
        "\n",
        "    #self.conv3 = nn.Conv2d(12, 24, 3)\n",
        "    #self.pool3 = nn.MaxPool2d(kernel_size=2)\n",
        "    #self.batch4 = nn.BatchNorm2d(24)\n",
        "    #self.conv4 = nn.Conv2d(90, 90, 7)\n",
        "    #self.pool4 = nn.MaxPool2d(kernel_size=2)\n",
        "    self.fl = nn.Flatten()\n",
        "    #self.dp1 = nn.Dropout(0.6) # 0.7\n",
        "    self.fc1 = nn.Linear(169 * 12, 128)\n",
        "    self.dp2 = nn.Dropout(0.5) # 0.7\n",
        "    self.activation1 = nn.LeakyReLU()\n",
        "    #self.fc2 = nn.Linear(128, 128)\n",
        "    #self.activation2 = nn.ELU()\n",
        "    self.fc2 = nn.Linear(128, 2)\n",
        "    #self.sm = nn.Softmax(dim=0)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.pool1(self.conv1(self.batch1(x)))\n",
        "    x = self.pool2(self.conv2(self.batch2(x)))\n",
        "    x = self.batch3(x)\n",
        "    #x += identity\n",
        "    #x = self.batch2(x)\n",
        "    #x = self.batch4(x)\n",
        "    #x = self.pool4(self.conv4(self.batch4(x)))\n",
        "    x = self.fl(x)\n",
        "    #x = self.dp1(x)\n",
        "    x = self.activation1(self.dp2(self.fc1(x)))\n",
        "    #x = self.activation2(self.fc2(x))\n",
        "    #x = self.sm(x)\n",
        "    #x = self.sm(self.fc3(x))\n",
        "    x = self.fc2(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "model = NetWork()\n",
        "model = model.to(DEVICE)\n"
      ],
      "metadata": {
        "id": "mRLtd_LU6fQa"
      },
      "id": "mRLtd_LU6fQa",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Опишем функции для обучения и тестирования модели"
      ],
      "metadata": {
        "id": "mief9swz22lR"
      },
      "id": "mief9swz22lR"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "NI0r2apuTXtS",
      "metadata": {
        "id": "NI0r2apuTXtS"
      },
      "outputs": [],
      "source": [
        "def fit_epoch(model, train_loader, criterion, optimizer):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "    processed_data = 0\n",
        "  \n",
        "    for inputs, labels in train_loader:\n",
        "        inputs = inputs.to(DEVICE)\n",
        "        labels = labels.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        preds = torch.argmax(outputs, 1)\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        running_corrects += torch.sum(preds == labels.data)\n",
        "        processed_data += inputs.size(0)\n",
        "              \n",
        "    train_loss = running_loss / processed_data\n",
        "    train_acc = running_corrects.cpu().numpy() / processed_data\n",
        "    return train_loss, train_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "35144ba0",
      "metadata": {
        "id": "35144ba0"
      },
      "outputs": [],
      "source": [
        "def eval_epoch(model, val_loader, criterion):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "    corrects_top3 = 0\n",
        "    processed_size = 0\n",
        "    predictions = []\n",
        "    answers = []\n",
        "    for inputs, labels in val_loader:\n",
        "        inputs = inputs.to(DEVICE)\n",
        "        labels = labels.to(DEVICE)\n",
        "        with torch.set_grad_enabled(False):\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            preds = torch.argmax(outputs, 1)\n",
        "            top3_preds = preds\n",
        "            if preds.ndim > 1:\n",
        "                _, top3_preds = torch.topk(outputs, k=3, dim=1)\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        for index in range(0, len(labels.data)):\n",
        "          if labels.data[index] in top3_preds[index]:\n",
        "            corrects_top3 += 1\n",
        "        running_corrects += torch.sum(preds == labels.data)\n",
        "        for pred in preds:\n",
        "          predictions.append(int(pred))\n",
        "        for label in labels.data:\n",
        "          answers.append(int(label))\n",
        "        processed_size += inputs.size(0)\n",
        "    val_loss = running_loss / processed_size\n",
        "    val_acc = running_corrects.double() / processed_size\n",
        "    val_acc_top3 = float(corrects_top3) / processed_size\n",
        "    return val_loss, val_acc, val_acc_top3, predictions, answers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "2b1b9afd",
      "metadata": {
        "id": "2b1b9afd"
      },
      "outputs": [],
      "source": [
        "def train(train_dataset, test_dataset, model, epochs, batch_size):\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    history = []\n",
        "    predictions = []\n",
        "    log_template = \"\\nEpoch {ep:03d} train_loss: {t_loss:0.4f} \\\n",
        "    val_loss {v_loss:0.4f} train_acc {t_acc:0.4f} val_acc {v_acc:0.4f} val_acc_top3 {v_acc_top3:0.4f}\"\n",
        "\n",
        "    with tqdm(desc=\"epoch\", total=epochs) as pbar_outer:\n",
        "        opt = torch.optim.Adam(model.parameters())\n",
        "        scheduler = torch.optim.lr_scheduler.ExponentialLR(opt,\n",
        "          gamma=0.95)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            train_loss, train_acc = fit_epoch(model, train_loader, criterion, opt)\n",
        "            scheduler.step()\n",
        "            val_loss, val_acc, val_acc_top3, predictions, answers = eval_epoch(model, val_loader, criterion)\n",
        "            history.append((train_loss, train_acc, val_loss, val_acc))\n",
        "            \n",
        "            pbar_outer.update(1)\n",
        "            tqdm.write(log_template.format(ep=epoch+1, t_loss=train_loss,\\\n",
        "                                           v_loss=val_loss, t_acc=train_acc, v_acc=val_acc, v_acc_top3=val_acc_top3))\n",
        "            \n",
        "    return history, predictions, answers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "1c146a9d",
      "metadata": {
        "id": "1c146a9d"
      },
      "outputs": [],
      "source": [
        "def predict(model, test_loader):\n",
        "    with torch.no_grad():\n",
        "        logits = []\n",
        "        for inputs in test_loader:\n",
        "            inputs = inputs.to(DEVICE)\n",
        "            model.eval()\n",
        "            outputs = model(inputs).cpu()\n",
        "            logits.append(outputs)\n",
        "            \n",
        "    probs = nn.functional.softmax(torch.cat(logits), dim=-1).numpy()\n",
        "    return probs"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Бинарная классификация**\n",
        "\n",
        "Обучим и протестируем нашу модель"
      ],
      "metadata": {
        "id": "ffhinTYE282u"
      },
      "id": "ffhinTYE282u"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af08e744",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "af08e744",
        "outputId": "6e692285-1f68-4d8b-96c0-93ab95c12aaf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  10%|█         | 1/10 [00:14<02:07, 14.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 001 train_loss: 0.1718     val_loss 0.2807 train_acc 0.9283 val_acc 0.8771 val_acc_top3 0.8771\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  20%|██        | 2/10 [00:28<01:53, 14.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 002 train_loss: 0.1316     val_loss 0.2887 train_acc 0.9517 val_acc 0.8818 val_acc_top3 0.8818\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  30%|███       | 3/10 [00:42<01:39, 14.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 003 train_loss: 0.0963     val_loss 0.2229 train_acc 0.9712 val_acc 0.9238 val_acc_top3 0.9238\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  40%|████      | 4/10 [00:57<01:26, 14.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 004 train_loss: 0.0623     val_loss 0.2352 train_acc 0.9790 val_acc 0.9114 val_acc_top3 0.9114\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  50%|█████     | 5/10 [01:11<01:12, 14.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 005 train_loss: 0.0387     val_loss 0.2128 train_acc 0.9879 val_acc 0.9269 val_acc_top3 0.9269\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  60%|██████    | 6/10 [01:26<00:58, 14.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 006 train_loss: 0.0290     val_loss 0.2333 train_acc 0.9934 val_acc 0.9191 val_acc_top3 0.9191\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  70%|███████   | 7/10 [01:40<00:43, 14.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 007 train_loss: 0.0277     val_loss 0.2271 train_acc 0.9922 val_acc 0.9316 val_acc_top3 0.9316\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  80%|████████  | 8/10 [01:55<00:28, 14.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 008 train_loss: 0.0226     val_loss 0.2791 train_acc 0.9942 val_acc 0.9129 val_acc_top3 0.9129\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  90%|█████████ | 9/10 [02:09<00:14, 14.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 009 train_loss: 0.0169     val_loss 0.2300 train_acc 0.9965 val_acc 0.9300 val_acc_top3 0.9300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch: 100%|██████████| 10/10 [02:23<00:00, 14.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 010 train_loss: 0.0108     val_loss 0.2457 train_acc 0.9988 val_acc 0.9378 val_acc_top3 0.9378\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "history, predictions, answers = train(train_dataset, test_dataset, model=model, epochs=10, batch_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5037f120",
      "metadata": {
        "id": "5037f120"
      },
      "outputs": [],
      "source": [
        "loss, acc, val_loss, val_acc = zip(*history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c51211c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 773
        },
        "id": "7c51211c",
        "outputId": "8b637a44-3a0b-44d2-b786-6d745ebe6cb3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x900 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.figure(figsize=(15, 9))\n",
        "plt.plot(loss, label=\"train_loss\")\n",
        "plt.plot(val_loss, label=\"val_loss\")\n",
        "plt.legend(loc='best')\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Многоклассовая классификация**\n",
        "\n",
        "Подготовим данные для многоклассовой классификации, сохраняя в качестве меток полные имена папок\n"
      ],
      "metadata": {
        "id": "9mEQWm6H3PZT"
      },
      "id": "9mEQWm6H3PZT"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "gZZ0HqpMd5P2",
      "metadata": {
        "id": "gZZ0HqpMd5P2"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "_y = [path.parent.name for path in files]\n",
        "train_data_multi, test_data_multi = train_test_split(files, train_size=0.8, stratify=_y)\n",
        "\n",
        "train_dataset_multi = PetFacesDataset(train_data_multi, \"train\", task=\"multi\")\n",
        "test_dataset_multi = PetFacesDataset(test_data_multi, \"val\", task=\"multi\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Изменим последний слой модели под задачу многоклассовой классификации"
      ],
      "metadata": {
        "id": "jx6PB8gc3s6p"
      },
      "id": "jx6PB8gc3s6p"
    },
    {
      "cell_type": "code",
      "source": [
        "model.fc2 = nn.Linear(128, 35)\n",
        "model = model.to(DEVICE)"
      ],
      "metadata": {
        "id": "YrO4ty39E7jX"
      },
      "id": "YrO4ty39E7jX",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dX_DRtaxeoVu",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dX_DRtaxeoVu",
        "outputId": "28f8b59d-5457-45d7-cd74-026c554e9a6b",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:   7%|▋         | 1/15 [00:14<03:25, 14.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 001 train_loss: 0.6312     val_loss 1.4984 train_acc 0.8072 val_acc 0.5832 val_acc_top3 0.5832\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  13%|█▎        | 2/15 [00:30<03:16, 15.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 002 train_loss: 0.5212     val_loss 1.4271 train_acc 0.8435 val_acc 0.6096 val_acc_top3 0.6096\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  20%|██        | 3/15 [00:44<02:59, 14.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 003 train_loss: 0.3959     val_loss 1.4751 train_acc 0.8863 val_acc 0.6065 val_acc_top3 0.6065\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  27%|██▋       | 4/15 [00:59<02:43, 14.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 004 train_loss: 0.3475     val_loss 1.5592 train_acc 0.8972 val_acc 0.6050 val_acc_top3 0.6050\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  33%|███▎      | 5/15 [01:14<02:27, 14.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 005 train_loss: 0.3246     val_loss 1.4927 train_acc 0.9065 val_acc 0.6065 val_acc_top3 0.6065\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  40%|████      | 6/15 [01:28<02:11, 14.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 006 train_loss: 0.2599     val_loss 1.5320 train_acc 0.9295 val_acc 0.6252 val_acc_top3 0.6252\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  47%|████▋     | 7/15 [01:46<02:05, 15.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 007 train_loss: 0.2293     val_loss 1.4961 train_acc 0.9381 val_acc 0.6221 val_acc_top3 0.6221\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  53%|█████▎    | 8/15 [02:01<01:48, 15.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 008 train_loss: 0.2163     val_loss 1.5795 train_acc 0.9443 val_acc 0.6174 val_acc_top3 0.6174\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  60%|██████    | 9/15 [02:16<01:31, 15.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 009 train_loss: 0.1751     val_loss 1.5435 train_acc 0.9537 val_acc 0.6096 val_acc_top3 0.6096\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  67%|██████▋   | 10/15 [02:30<01:14, 14.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 010 train_loss: 0.1556     val_loss 1.5853 train_acc 0.9622 val_acc 0.6205 val_acc_top3 0.6205\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  73%|███████▎  | 11/15 [02:44<00:59, 14.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 011 train_loss: 0.1354     val_loss 1.5580 train_acc 0.9653 val_acc 0.6221 val_acc_top3 0.6221\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  80%|████████  | 12/15 [02:59<00:44, 14.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 012 train_loss: 0.1438     val_loss 1.5965 train_acc 0.9607 val_acc 0.6221 val_acc_top3 0.6221\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  87%|████████▋ | 13/15 [03:15<00:30, 15.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 013 train_loss: 0.1350     val_loss 1.6291 train_acc 0.9681 val_acc 0.6112 val_acc_top3 0.6112\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  93%|█████████▎| 14/15 [03:30<00:15, 15.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 014 train_loss: 0.1167     val_loss 1.6089 train_acc 0.9735 val_acc 0.6345 val_acc_top3 0.6345\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch: 100%|██████████| 15/15 [03:45<00:00, 15.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 015 train_loss: 0.1011     val_loss 1.6278 train_acc 0.9770 val_acc 0.6252 val_acc_top3 0.6252\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "history_, predictions_, answers_ = train(train_dataset_multi, test_dataset_multi, model=model, epochs=15, batch_size=64)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "EdshtTtqnHPg",
      "metadata": {
        "id": "EdshtTtqnHPg"
      },
      "source": [
        "**Creating confusion matrix**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Y0Rl8zIwnNlf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0Rl8zIwnNlf",
        "outputId": "25f4da0c-7739-42b4-f374-717b15862577"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "35"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "import numpy as np\n",
        "classes = list(np.unique(_y))\n",
        "classes\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "len(classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Строка отвечает за правильный ответ, то есть за метку класса, к которому принадлежит объект, а столбец за прогноз модели, тогда на пересечении столбца и строки будет стоять число объектов, для которых класс соответствует строке, а прогноз модели-столбцу"
      ],
      "metadata": {
        "id": "NMXPoz4su6eB"
      },
      "id": "NMXPoz4su6eB"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WRzU_2v7npuy",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        },
        "id": "WRzU_2v7npuy",
        "outputId": "007b3ebe-ca2f-478c-9abc-409bbf3de640"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                   cat_Abyssinian  cat_Bengal  cat_Birman  cat_Bombay  \\\n",
              "cat_Abyssinian                 11           3           0           0   \n",
              "cat_Bengal                      2           6           1           0   \n",
              "cat_Birman                      0           0          17           0   \n",
              "cat_Bombay                      0           0           0          15   \n",
              "cat_British                     0           0           0           1   \n",
              "cat_Egyptian                    0           3           0           1   \n",
              "cat_Maine                       2           2           0           0   \n",
              "cat_Persian                     0           0           1           0   \n",
              "cat_Ragdoll                     0           0           2           0   \n",
              "cat_Russian                     0           0           0           0   \n",
              "cat_Siamese                     0           0           1           0   \n",
              "cat_Sphynx                      0           1           0           0   \n",
              "dog_american                    0           0           0           0   \n",
              "dog_basset                      0           0           0           0   \n",
              "dog_beagle                      0           0           0           0   \n",
              "dog_boxer                       0           0           1           0   \n",
              "dog_chihuahua                   0           1           0           0   \n",
              "dog_english                     1           0           0           0   \n",
              "dog_german                      0           0           0           0   \n",
              "dog_great                       0           0           0           0   \n",
              "dog_havanese                    0           0           0           0   \n",
              "dog_japanese                    0           0           0           0   \n",
              "dog_keeshond                    0           0           0           1   \n",
              "dog_leonberger                  0           0           0           0   \n",
              "dog_miniature                   0           1           0           0   \n",
              "dog_newfoundland                0           0           0           0   \n",
              "dog_pomeranian                  0           0           0           0   \n",
              "dog_pug                         0           0           1           0   \n",
              "dog_saint                       0           0           0           0   \n",
              "dog_samoyed                     0           0           0           0   \n",
              "dog_scottish                    0           0           0           1   \n",
              "dog_shiba                       0           0           0           0   \n",
              "dog_staffordshire               0           0           0           0   \n",
              "dog_wheaten                     0           0           0           0   \n",
              "dog_yorkshire                   0           0           0           0   \n",
              "\n",
              "                   cat_British  cat_Egyptian  cat_Maine  cat_Persian  \\\n",
              "cat_Abyssinian               0             0          0            1   \n",
              "cat_Bengal                   0             3          1            1   \n",
              "cat_Birman                   0             0          0            1   \n",
              "cat_Bombay                   0             0          0            0   \n",
              "cat_British                 19             0          0            0   \n",
              "cat_Egyptian                 1             7          0            0   \n",
              "cat_Maine                    0             0         14            0   \n",
              "cat_Persian                  0             0          0           18   \n",
              "cat_Ragdoll                  0             0          0            2   \n",
              "cat_Russian                  5             0          0            0   \n",
              "cat_Siamese                  0             0          0            0   \n",
              "cat_Sphynx                   0             0          0            0   \n",
              "dog_american                 0             0          0            0   \n",
              "dog_basset                   0             0          0            0   \n",
              "dog_beagle                   0             0          0            0   \n",
              "dog_boxer                    0             0          0            0   \n",
              "dog_chihuahua                0             0          0            0   \n",
              "dog_english                  0             1          0            0   \n",
              "dog_german                   0             0          0            0   \n",
              "dog_great                    0             0          0            0   \n",
              "dog_havanese                 1             0          0            0   \n",
              "dog_japanese                 0             0          0            0   \n",
              "dog_keeshond                 0             0          0            0   \n",
              "dog_leonberger               0             0          0            0   \n",
              "dog_miniature                0             0          0            0   \n",
              "dog_newfoundland             0             0          0            0   \n",
              "dog_pomeranian               0             0          0            0   \n",
              "dog_pug                      0             0          0            0   \n",
              "dog_saint                    0             0          0            0   \n",
              "dog_samoyed                  0             0          0            0   \n",
              "dog_scottish                 0             0          0            0   \n",
              "dog_shiba                    0             0          0            0   \n",
              "dog_staffordshire            0             0          0            0   \n",
              "dog_wheaten                  0             0          0            0   \n",
              "dog_yorkshire                0             0          0            0   \n",
              "\n",
              "                   cat_Ragdoll  cat_Russian  ...  dog_newfoundland  \\\n",
              "cat_Abyssinian               1            0  ...                 0   \n",
              "cat_Bengal                   0            0  ...                 0   \n",
              "cat_Birman                   1            0  ...                 0   \n",
              "cat_Bombay                   0            0  ...                 0   \n",
              "cat_British                  0            0  ...                 0   \n",
              "cat_Egyptian                 0            0  ...                 0   \n",
              "cat_Maine                    0            0  ...                 0   \n",
              "cat_Persian                  0            0  ...                 0   \n",
              "cat_Ragdoll                 12            0  ...                 0   \n",
              "cat_Russian                  0           13  ...                 0   \n",
              "cat_Siamese                  1            1  ...                 0   \n",
              "cat_Sphynx                   1            1  ...                 0   \n",
              "dog_american                 0            0  ...                 0   \n",
              "dog_basset                   0            0  ...                 1   \n",
              "dog_beagle                   0            0  ...                 0   \n",
              "dog_boxer                    0            0  ...                 1   \n",
              "dog_chihuahua                1            0  ...                 0   \n",
              "dog_english                  0            0  ...                 1   \n",
              "dog_german                   0            0  ...                 1   \n",
              "dog_great                    0            0  ...                 0   \n",
              "dog_havanese                 0            0  ...                 3   \n",
              "dog_japanese                 0            0  ...                 1   \n",
              "dog_keeshond                 0            0  ...                 0   \n",
              "dog_leonberger               0            0  ...                 4   \n",
              "dog_miniature                0            0  ...                 0   \n",
              "dog_newfoundland             0            0  ...                14   \n",
              "dog_pomeranian               0            0  ...                 0   \n",
              "dog_pug                      0            0  ...                 0   \n",
              "dog_saint                    0            0  ...                 1   \n",
              "dog_samoyed                  0            0  ...                 0   \n",
              "dog_scottish                 0            0  ...                 2   \n",
              "dog_shiba                    0            0  ...                 0   \n",
              "dog_staffordshire            0            0  ...                 0   \n",
              "dog_wheaten                  0            0  ...                 0   \n",
              "dog_yorkshire                0            0  ...                 1   \n",
              "\n",
              "                   dog_pomeranian  dog_pug  dog_saint  dog_samoyed  \\\n",
              "cat_Abyssinian                  0        0          0            0   \n",
              "cat_Bengal                      0        0          0            0   \n",
              "cat_Birman                      0        0          0            0   \n",
              "cat_Bombay                      0        0          0            0   \n",
              "cat_British                     0        0          0            0   \n",
              "cat_Egyptian                    0        0          0            0   \n",
              "cat_Maine                       0        0          0            0   \n",
              "cat_Persian                     0        0          0            0   \n",
              "cat_Ragdoll                     0        0          0            0   \n",
              "cat_Russian                     0        0          0            0   \n",
              "cat_Siamese                     0        0          0            0   \n",
              "cat_Sphynx                      0        0          0            0   \n",
              "dog_american                    2        1          1            0   \n",
              "dog_basset                      0        0          0            0   \n",
              "dog_beagle                      0        0          0            0   \n",
              "dog_boxer                       0        0          0            0   \n",
              "dog_chihuahua                   1        0          0            0   \n",
              "dog_english                     0        0          0            0   \n",
              "dog_german                      0        0          1            0   \n",
              "dog_great                       0        0          1            1   \n",
              "dog_havanese                    0        0          0            0   \n",
              "dog_japanese                    0        0          2            0   \n",
              "dog_keeshond                    0        0          0            0   \n",
              "dog_leonberger                  0        0          0            0   \n",
              "dog_miniature                   0        1          0            0   \n",
              "dog_newfoundland                0        0          0            0   \n",
              "dog_pomeranian                 15        0          0            2   \n",
              "dog_pug                         0       12          1            0   \n",
              "dog_saint                       0        0          9            0   \n",
              "dog_samoyed                     1        0          0            8   \n",
              "dog_scottish                    0        0          0            0   \n",
              "dog_shiba                       0        0          0            0   \n",
              "dog_staffordshire               0        0          1            0   \n",
              "dog_wheaten                     0        0          0            0   \n",
              "dog_yorkshire                   0        0          0            0   \n",
              "\n",
              "                   dog_scottish  dog_shiba  dog_staffordshire  dog_wheaten  \\\n",
              "cat_Abyssinian                0          0                  0            0   \n",
              "cat_Bengal                    0          0                  0            0   \n",
              "cat_Birman                    0          0                  0            0   \n",
              "cat_Bombay                    0          1                  0            0   \n",
              "cat_British                   0          0                  0            0   \n",
              "cat_Egyptian                  0          0                  0            0   \n",
              "cat_Maine                     0          0                  0            0   \n",
              "cat_Persian                   0          0                  0            0   \n",
              "cat_Ragdoll                   0          0                  0            0   \n",
              "cat_Russian                   0          0                  0            0   \n",
              "cat_Siamese                   0          0                  0            0   \n",
              "cat_Sphynx                    0          0                  0            0   \n",
              "dog_american                  0          0                  1            0   \n",
              "dog_basset                    0          0                  1            0   \n",
              "dog_beagle                    0          1                  0            0   \n",
              "dog_boxer                     0          0                  3            0   \n",
              "dog_chihuahua                 0          1                  0            0   \n",
              "dog_english                   0          0                  0            0   \n",
              "dog_german                    0          0                  0            0   \n",
              "dog_great                     0          0                  0            3   \n",
              "dog_havanese                  0          1                  0            1   \n",
              "dog_japanese                  0          1                  0            0   \n",
              "dog_keeshond                  0          0                  1            0   \n",
              "dog_leonberger                0          0                  0            0   \n",
              "dog_miniature                 0          0                  0            0   \n",
              "dog_newfoundland              0          0                  0            0   \n",
              "dog_pomeranian                0          0                  0            0   \n",
              "dog_pug                       1          0                  0            0   \n",
              "dog_saint                     0          0                  0            0   \n",
              "dog_samoyed                   0          1                  0            0   \n",
              "dog_scottish                  5          0                  1            0   \n",
              "dog_shiba                     0         14                  0            0   \n",
              "dog_staffordshire             1          0                 11            0   \n",
              "dog_wheaten                   0          0                  0           11   \n",
              "dog_yorkshire                 0          0                  0            3   \n",
              "\n",
              "                   dog_yorkshire  \n",
              "cat_Abyssinian                 0  \n",
              "cat_Bengal                     0  \n",
              "cat_Birman                     0  \n",
              "cat_Bombay                     0  \n",
              "cat_British                    0  \n",
              "cat_Egyptian                   0  \n",
              "cat_Maine                      1  \n",
              "cat_Persian                    0  \n",
              "cat_Ragdoll                    0  \n",
              "cat_Russian                    0  \n",
              "cat_Siamese                    0  \n",
              "cat_Sphynx                     0  \n",
              "dog_american                   0  \n",
              "dog_basset                     0  \n",
              "dog_beagle                     0  \n",
              "dog_boxer                      0  \n",
              "dog_chihuahua                  0  \n",
              "dog_english                    0  \n",
              "dog_german                     0  \n",
              "dog_great                      0  \n",
              "dog_havanese                   0  \n",
              "dog_japanese                   0  \n",
              "dog_keeshond                   1  \n",
              "dog_leonberger                 0  \n",
              "dog_miniature                  0  \n",
              "dog_newfoundland               0  \n",
              "dog_pomeranian                 0  \n",
              "dog_pug                        0  \n",
              "dog_saint                      0  \n",
              "dog_samoyed                    0  \n",
              "dog_scottish                   0  \n",
              "dog_shiba                      1  \n",
              "dog_staffordshire              0  \n",
              "dog_wheaten                    0  \n",
              "dog_yorkshire                  6  \n",
              "\n",
              "[35 rows x 35 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4a283f62-4659-4d2f-b619-79497c8911c3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cat_Abyssinian</th>\n",
              "      <th>cat_Bengal</th>\n",
              "      <th>cat_Birman</th>\n",
              "      <th>cat_Bombay</th>\n",
              "      <th>cat_British</th>\n",
              "      <th>cat_Egyptian</th>\n",
              "      <th>cat_Maine</th>\n",
              "      <th>cat_Persian</th>\n",
              "      <th>cat_Ragdoll</th>\n",
              "      <th>cat_Russian</th>\n",
              "      <th>...</th>\n",
              "      <th>dog_newfoundland</th>\n",
              "      <th>dog_pomeranian</th>\n",
              "      <th>dog_pug</th>\n",
              "      <th>dog_saint</th>\n",
              "      <th>dog_samoyed</th>\n",
              "      <th>dog_scottish</th>\n",
              "      <th>dog_shiba</th>\n",
              "      <th>dog_staffordshire</th>\n",
              "      <th>dog_wheaten</th>\n",
              "      <th>dog_yorkshire</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>cat_Abyssinian</th>\n",
              "      <td>11</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cat_Bengal</th>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cat_Birman</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cat_Bombay</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cat_British</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>19</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cat_Egyptian</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cat_Maine</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cat_Persian</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cat_Ragdoll</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cat_Russian</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cat_Siamese</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cat_Sphynx</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dog_american</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dog_basset</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dog_beagle</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dog_boxer</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dog_chihuahua</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dog_english</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dog_german</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dog_great</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dog_havanese</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dog_japanese</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dog_keeshond</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dog_leonberger</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dog_miniature</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dog_newfoundland</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dog_pomeranian</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dog_pug</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dog_saint</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dog_samoyed</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dog_scottish</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dog_shiba</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dog_staffordshire</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dog_wheaten</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dog_yorkshire</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>35 rows × 35 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4a283f62-4659-4d2f-b619-79497c8911c3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4a283f62-4659-4d2f-b619-79497c8911c3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4a283f62-4659-4d2f-b619-79497c8911c3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 25
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Total number of columns (35) exceeds max_columns (20) limiting to first (20) columns.\n"
          ]
        }
      ],
      "source": [
        "cf_matrix = confusion_matrix(answers_, predictions_)\n",
        "df_cm = pd.DataFrame(cf_matrix, index=classes, columns=classes)\n",
        "df_cm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Выполним оптимизацию гиперпараметоров**\n",
        "\n",
        "Выбор архитектуры был выполнен ранее. В качестве слоёв были выбраны convolutional слой, maxpool и batchnorm и два полносвязных слоя. Для выбора оптимальной архитектуры я брал сначала четыре таких слоя состоящих из свёртки, пулинга и батчнормы, затем три и два, меняя также размер пулинга и число карт активаций после свёртки. Нейросеть с 3 и 4 свёрточными слоями очень быстро переобучалась, выдавая на тренировочной выборке долю правильных ответов порядка 0.98, в то время как на тестовой выборке это значение не поднималось выше 0.6. Оптимальным с точки зрения количества слоёв оказалось выбирать два таких слоя.\n",
        "Также в качестве оптимизаторов использовались Adam и AdamW, как лучшие алгоритмы оптимизации. Второй использовался в надежде справиться с переобучением, что частично было достигнуто, однако итоговое качество на тестовой выборке не выросло.\n"
      ],
      "metadata": {
        "id": "5vaJeHR-AONU"
      },
      "id": "5vaJeHR-AONU"
    },
    {
      "cell_type": "code",
      "source": [
        "class AdaptiveNetWork(nn.Module):\n",
        "  def __init__(self, kernel_size=3):\n",
        "    super(AdaptiveNetWork, self).__init__()\n",
        "    self.batch1 = nn.BatchNorm2d(3)\n",
        "    self.conv1 = nn.Conv2d(3, 6, kernel_size)\n",
        "    self.pool1 = nn.MaxPool2d(kernel_size=4)\n",
        "    self.batch2 = nn.BatchNorm2d(6)\n",
        "    self.conv2 = nn.Conv2d(6, 12, kernel_size)\n",
        "    self.pool2 = nn.MaxPool2d(kernel_size=4)\n",
        "    self.batch3 = nn.BatchNorm2d(12)\n",
        "    self.fl = nn.Flatten()\n",
        "    feature_count = ((224 - kernel_size + 1) // 4 - kernel_size + 1) // 4\n",
        "    self.fc1 = nn.Linear(feature_count ** 2 * 12, 128)\n",
        "    self.dp2 = nn.Dropout(0.6) # 0.7\n",
        "    self.activation1 = nn.LeakyReLU()\n",
        "    self.fc2 = nn.Linear(128, 35)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.pool1(self.conv1(self.batch1(x)))\n",
        "    x = self.pool2(self.conv2(self.batch2(x)))\n",
        "    x = self.batch3(x)\n",
        "    x = self.fl(x)\n",
        "    x = self.activation1(self.dp2(self.fc1(x)))\n",
        "    x = self.fc2(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "4xAZjpVRCSsc"
      },
      "id": "4xAZjpVRCSsc",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_search(train_dataset, test_dataset, model, epochs, batch_size, learning_rate):\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    history = []\n",
        "    predictions = []\n",
        "    log_template = \"\\nEpoch {ep:03d} train_loss: {t_loss:0.4f} \\\n",
        "    val_loss {v_loss:0.4f} train_acc {t_acc:0.4f} val_acc {v_acc:0.4f} val_acc_top3 {v_acc_top3:0.4f}\"\n",
        "\n",
        "    with tqdm(desc=\"epoch\", total=epochs) as pbar_outer:\n",
        "        opt = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "        scheduler = torch.optim.lr_scheduler.ExponentialLR(opt,\n",
        "          gamma=0.95)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        for epoch in range(epochs):\n",
        "            train_loss, train_acc = fit_epoch(model, train_loader, criterion, opt)\n",
        "            scheduler.step()\n",
        "            val_loss, val_acc, val_acc_top3, predictions, answers = eval_epoch(model, val_loader, criterion)\n",
        "            history.append((train_loss, train_acc, val_loss, val_acc))\n",
        "            \n",
        "            pbar_outer.update(1)\n",
        "            tqdm.write(log_template.format(ep=epoch+1, t_loss=train_loss,\\\n",
        "                                           v_loss=val_loss, t_acc=train_acc, v_acc=val_acc, v_acc_top3=val_acc_top3))\n",
        "            \n",
        "    return history"
      ],
      "metadata": {
        "id": "0i7TXbYHBlw_"
      },
      "id": "0i7TXbYHBlw_",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для поиска оптимальных параметров воспользуемся поиском по сетке, то есть переберём все комбинации параметров из некоторой \"сетки\". Такой подход редко используют при обучении нейронных сетей, так как они долго обучаются и на одной комбинации гиперпараметров, не говоря уже о нескольких. Но в нашем случае обучение занимает пару минут, поэтому вариант перебора возможен."
      ],
      "metadata": {
        "id": "1QL668aR7gAx"
      },
      "id": "1QL668aR7gAx"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae07742b",
      "metadata": {
        "id": "ae07742b"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "def grid_search(lr, kernel_sizes):\n",
        "    split_count = len(lr) * len(kernel_sizes)\n",
        "    kf = StratifiedKFold(n_splits=split_count)\n",
        "    best_lr = lr[0]\n",
        "    best_kernel_size = kernel_sizes[0]\n",
        "    curr_result = 0.0\n",
        "    for learning_rate in lr:\n",
        "        for kernel_size in kernel_sizes:\n",
        "            X_train, X_val = next(kf.split(files, _y))\n",
        "            train_data = [files[element] for element in X_train]\n",
        "            val_data = [files[element] for element in X_val]\n",
        "            train_dataset = PetFacesDataset(train_data, \"train\", \"multi\")\n",
        "            val_dataset = PetFacesDataset(val_data, \"val\", \"multi\")\n",
        "            search_model = AdaptiveNetWork(kernel_size)\n",
        "            search_model = search_model.to(DEVICE)\n",
        "            print(\"learning_rate=\", learning_rate, \"kernel_size=\", kernel_size)\n",
        "            history = train_search(train_dataset, val_dataset, search_model, 15, 64, learning_rate)\n",
        "            result = float(history[-1][3])\n",
        "            if result > curr_result:\n",
        "                best_lr = learning_rate\n",
        "                best_kernel_size = kernel_size\n",
        "            print(\"result:\", result)\n",
        "    return best_lr, best_kernel_size"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "На практике обычно не используют фильтры чётного размера, и современные модели не используют фильтры больше 7 на 7. Поэтому я остановился на фильтрах размерами 3 на 3, 5 на 5 и 7 на 7. Использование батчнормы делает обучение нейросети более стабильным и позволяет брать learning rate больше, что мы и сделаем."
      ],
      "metadata": {
        "id": "zHQwYa0EJVTa"
      },
      "id": "zHQwYa0EJVTa"
    },
    {
      "cell_type": "code",
      "source": [
        "params = {\n",
        "    \"lr\": [0.001, 0.002, 0.004, 0.006, 0.01, 0.05],\n",
        "    \"kernel_sizes\": [3, 5, 7]\n",
        "}\n",
        "\n",
        "best_params = grid_search(**params)\n",
        "print(best_params)"
      ],
      "metadata": {
        "id": "OFBMaVw9FCcE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b540e626-ccaa-4cf7-8277-9882971a220d"
      },
      "id": "OFBMaVw9FCcE",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "learning_rate= 0.001 kernel_size= 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:   7%|▋         | 1/15 [00:16<03:48, 16.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 001 train_loss: 3.0620     val_loss 2.2351 train_acc 0.1708 val_acc 0.4078 val_acc_top3 0.4078\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  13%|█▎        | 2/15 [00:30<03:18, 15.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 002 train_loss: 2.2407     val_loss 1.9042 train_acc 0.3750 val_acc 0.5140 val_acc_top3 0.5140\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  20%|██        | 3/15 [00:45<02:58, 14.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 003 train_loss: 1.7806     val_loss 1.6348 train_acc 0.4809 val_acc 0.5475 val_acc_top3 0.5475\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  27%|██▋       | 4/15 [00:59<02:41, 14.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 004 train_loss: 1.5090     val_loss 1.4837 train_acc 0.5683 val_acc 0.5698 val_acc_top3 0.5698\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  33%|███▎      | 5/15 [01:15<02:30, 15.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 005 train_loss: 1.2842     val_loss 1.4538 train_acc 0.6247 val_acc 0.5810 val_acc_top3 0.5810\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  40%|████      | 6/15 [01:30<02:15, 15.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 006 train_loss: 1.0992     val_loss 1.3449 train_acc 0.6765 val_acc 0.6201 val_acc_top3 0.6201\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  47%|████▋     | 7/15 [01:46<02:02, 15.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 007 train_loss: 1.0215     val_loss 1.3966 train_acc 0.7038 val_acc 0.6034 val_acc_top3 0.6034\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  53%|█████▎    | 8/15 [02:01<01:46, 15.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 008 train_loss: 0.9114     val_loss 1.3165 train_acc 0.7332 val_acc 0.6034 val_acc_top3 0.6034\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  60%|██████    | 9/15 [02:15<01:30, 15.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 009 train_loss: 0.7703     val_loss 1.3438 train_acc 0.7767 val_acc 0.6145 val_acc_top3 0.6145\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  67%|██████▋   | 10/15 [02:30<01:14, 14.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 010 train_loss: 0.6959     val_loss 1.3168 train_acc 0.7968 val_acc 0.6201 val_acc_top3 0.6201\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  73%|███████▎  | 11/15 [02:45<01:00, 15.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 011 train_loss: 0.6267     val_loss 1.3841 train_acc 0.8156 val_acc 0.5922 val_acc_top3 0.5922\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  80%|████████  | 12/15 [03:00<00:44, 14.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 012 train_loss: 0.5724     val_loss 1.3651 train_acc 0.8400 val_acc 0.5922 val_acc_top3 0.5922\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  87%|████████▋ | 13/15 [03:14<00:29, 14.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 013 train_loss: 0.5147     val_loss 1.3489 train_acc 0.8453 val_acc 0.5978 val_acc_top3 0.5978\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  93%|█████████▎| 14/15 [03:29<00:14, 14.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 014 train_loss: 0.4979     val_loss 1.3725 train_acc 0.8503 val_acc 0.6034 val_acc_top3 0.6034\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch: 100%|██████████| 15/15 [03:44<00:00, 14.99s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 015 train_loss: 0.4355     val_loss 1.4375 train_acc 0.8740 val_acc 0.5922 val_acc_top3 0.5922\n",
            "result: 0.5921787709497207\n",
            "learning_rate= 0.001 kernel_size= 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:   7%|▋         | 1/15 [00:17<04:03, 17.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 001 train_loss: 3.1229     val_loss 2.3931 train_acc 0.1544 val_acc 0.3855 val_acc_top3 0.3855\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  13%|█▎        | 2/15 [00:33<03:33, 16.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 002 train_loss: 2.3478     val_loss 1.9620 train_acc 0.3318 val_acc 0.4358 val_acc_top3 0.4358\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  20%|██        | 3/15 [00:49<03:15, 16.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 003 train_loss: 1.8708     val_loss 1.8101 train_acc 0.4631 val_acc 0.4693 val_acc_top3 0.4693\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  27%|██▋       | 4/15 [01:05<03:00, 16.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 004 train_loss: 1.6522     val_loss 1.6673 train_acc 0.5228 val_acc 0.4972 val_acc_top3 0.4972\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  33%|███▎      | 5/15 [01:21<02:42, 16.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 005 train_loss: 1.4185     val_loss 1.6412 train_acc 0.5923 val_acc 0.5140 val_acc_top3 0.5140\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  40%|████      | 6/15 [01:37<02:25, 16.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 006 train_loss: 1.2795     val_loss 1.5492 train_acc 0.6276 val_acc 0.5251 val_acc_top3 0.5251\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  47%|████▋     | 7/15 [01:54<02:09, 16.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 007 train_loss: 1.1037     val_loss 1.5229 train_acc 0.6781 val_acc 0.5754 val_acc_top3 0.5754\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  53%|█████▎    | 8/15 [02:10<01:54, 16.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 008 train_loss: 1.0211     val_loss 1.5463 train_acc 0.6890 val_acc 0.5698 val_acc_top3 0.5698\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  60%|██████    | 9/15 [02:26<01:37, 16.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 009 train_loss: 0.9280     val_loss 1.4665 train_acc 0.7365 val_acc 0.5642 val_acc_top3 0.5642\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  67%|██████▋   | 10/15 [02:41<01:19, 15.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 010 train_loss: 0.8095     val_loss 1.4871 train_acc 0.7586 val_acc 0.5363 val_acc_top3 0.5363\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  73%|███████▎  | 11/15 [02:57<01:03, 15.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 011 train_loss: 0.7191     val_loss 1.4475 train_acc 0.7916 val_acc 0.5475 val_acc_top3 0.5475\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  80%|████████  | 12/15 [03:13<00:47, 15.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 012 train_loss: 0.6549     val_loss 1.4697 train_acc 0.8090 val_acc 0.5866 val_acc_top3 0.5866\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  87%|████████▋ | 13/15 [03:28<00:31, 15.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 013 train_loss: 0.6233     val_loss 1.4832 train_acc 0.8137 val_acc 0.5698 val_acc_top3 0.5698\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  93%|█████████▎| 14/15 [03:44<00:15, 15.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 014 train_loss: 0.5526     val_loss 1.5155 train_acc 0.8397 val_acc 0.5363 val_acc_top3 0.5363\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch: 100%|██████████| 15/15 [03:59<00:00, 15.96s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 015 train_loss: 0.5092     val_loss 1.4282 train_acc 0.8536 val_acc 0.5698 val_acc_top3 0.5698\n",
            "result: 0.5698324022346369\n",
            "learning_rate= 0.001 kernel_size= 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:   7%|▋         | 1/15 [00:16<03:49, 16.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 001 train_loss: 3.1851     val_loss 2.5219 train_acc 0.1474 val_acc 0.3575 val_acc_top3 0.3575\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  13%|█▎        | 2/15 [00:31<03:26, 15.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 002 train_loss: 2.4317     val_loss 1.9872 train_acc 0.3176 val_acc 0.4637 val_acc_top3 0.4637\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  20%|██        | 3/15 [00:47<03:10, 15.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 003 train_loss: 2.0192     val_loss 1.7856 train_acc 0.4192 val_acc 0.4972 val_acc_top3 0.4972\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  27%|██▋       | 4/15 [01:04<02:56, 16.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 004 train_loss: 1.7010     val_loss 1.6576 train_acc 0.5082 val_acc 0.5419 val_acc_top3 0.5419\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  33%|███▎      | 5/15 [01:19<02:40, 16.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 005 train_loss: 1.4580     val_loss 1.5019 train_acc 0.5719 val_acc 0.5419 val_acc_top3 0.5419\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  40%|████      | 6/15 [01:35<02:22, 15.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 006 train_loss: 1.2713     val_loss 1.4651 train_acc 0.6263 val_acc 0.5866 val_acc_top3 0.5866\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  47%|████▋     | 7/15 [01:51<02:06, 15.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 007 train_loss: 1.1436     val_loss 1.3896 train_acc 0.6596 val_acc 0.5922 val_acc_top3 0.5922\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  53%|█████▎    | 8/15 [02:08<01:53, 16.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 008 train_loss: 0.9928     val_loss 1.3763 train_acc 0.6976 val_acc 0.6034 val_acc_top3 0.6034\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  60%|██████    | 9/15 [02:24<01:36, 16.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 009 train_loss: 0.8844     val_loss 1.3621 train_acc 0.7365 val_acc 0.5475 val_acc_top3 0.5475\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  67%|██████▋   | 10/15 [02:39<01:19, 15.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 010 train_loss: 0.8436     val_loss 1.3012 train_acc 0.7454 val_acc 0.6034 val_acc_top3 0.6034\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  73%|███████▎  | 11/15 [02:55<01:03, 15.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 011 train_loss: 0.7229     val_loss 1.3238 train_acc 0.7879 val_acc 0.5978 val_acc_top3 0.5978\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  80%|████████  | 12/15 [03:11<00:48, 16.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 012 train_loss: 0.6478     val_loss 1.3082 train_acc 0.8028 val_acc 0.5922 val_acc_top3 0.5922\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  87%|████████▋ | 13/15 [03:27<00:31, 15.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 013 train_loss: 0.6027     val_loss 1.2944 train_acc 0.8262 val_acc 0.6145 val_acc_top3 0.6145\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  93%|█████████▎| 14/15 [03:43<00:15, 15.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 014 train_loss: 0.5409     val_loss 1.3441 train_acc 0.8466 val_acc 0.5866 val_acc_top3 0.5866\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch: 100%|██████████| 15/15 [03:59<00:00, 15.96s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 015 train_loss: 0.5196     val_loss 1.3364 train_acc 0.8433 val_acc 0.5754 val_acc_top3 0.5754\n",
            "result: 0.5754189944134078\n",
            "learning_rate= 0.002 kernel_size= 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:   7%|▋         | 1/15 [00:14<03:16, 14.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 001 train_loss: 3.0940     val_loss 2.1433 train_acc 0.1824 val_acc 0.3520 val_acc_top3 0.3520\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  13%|█▎        | 2/15 [00:27<02:59, 13.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 002 train_loss: 2.2020     val_loss 1.8197 train_acc 0.3582 val_acc 0.4637 val_acc_top3 0.4637\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  20%|██        | 3/15 [00:41<02:45, 13.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 003 train_loss: 1.7798     val_loss 1.6754 train_acc 0.4763 val_acc 0.5196 val_acc_top3 0.5196\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  27%|██▋       | 4/15 [00:56<02:35, 14.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 004 train_loss: 1.5175     val_loss 1.5958 train_acc 0.5409 val_acc 0.4972 val_acc_top3 0.4972\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  33%|███▎      | 5/15 [01:09<02:20, 14.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 005 train_loss: 1.2981     val_loss 1.4808 train_acc 0.6029 val_acc 0.5698 val_acc_top3 0.5698\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  40%|████      | 6/15 [01:23<02:04, 13.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 006 train_loss: 1.1024     val_loss 1.4452 train_acc 0.6600 val_acc 0.5754 val_acc_top3 0.5754\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  47%|████▋     | 7/15 [01:37<01:50, 13.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 007 train_loss: 0.9478     val_loss 1.5354 train_acc 0.7061 val_acc 0.5307 val_acc_top3 0.5307\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  53%|█████▎    | 8/15 [01:50<01:36, 13.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 008 train_loss: 0.8478     val_loss 1.4404 train_acc 0.7342 val_acc 0.5698 val_acc_top3 0.5698\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  60%|██████    | 9/15 [02:05<01:24, 14.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 009 train_loss: 0.7570     val_loss 1.5158 train_acc 0.7582 val_acc 0.5475 val_acc_top3 0.5475\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  67%|██████▋   | 10/15 [02:19<01:10, 14.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 010 train_loss: 0.6463     val_loss 1.3607 train_acc 0.7892 val_acc 0.5866 val_acc_top3 0.5866\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  73%|███████▎  | 11/15 [02:33<00:55, 13.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 011 train_loss: 0.5991     val_loss 1.4713 train_acc 0.8173 val_acc 0.5866 val_acc_top3 0.5866\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  80%|████████  | 12/15 [02:47<00:41, 13.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 012 train_loss: 0.5687     val_loss 1.4874 train_acc 0.8146 val_acc 0.5866 val_acc_top3 0.5866\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  87%|████████▋ | 13/15 [03:00<00:27, 13.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 013 train_loss: 0.4705     val_loss 1.4103 train_acc 0.8503 val_acc 0.6034 val_acc_top3 0.6034\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  93%|█████████▎| 14/15 [03:14<00:13, 13.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 014 train_loss: 0.3963     val_loss 1.3776 train_acc 0.8813 val_acc 0.6145 val_acc_top3 0.6145\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch: 100%|██████████| 15/15 [03:29<00:00, 13.95s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 015 train_loss: 0.3670     val_loss 1.4475 train_acc 0.8912 val_acc 0.5922 val_acc_top3 0.5922\n",
            "result: 0.5921787709497207\n",
            "learning_rate= 0.002 kernel_size= 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:   7%|▋         | 1/15 [00:16<03:50, 16.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 001 train_loss: 3.1245     val_loss 2.2750 train_acc 0.1639 val_acc 0.3520 val_acc_top3 0.3520\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  13%|█▎        | 2/15 [00:33<03:37, 16.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 002 train_loss: 2.2652     val_loss 1.9058 train_acc 0.3496 val_acc 0.4749 val_acc_top3 0.4749\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  20%|██        | 3/15 [00:49<03:18, 16.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 003 train_loss: 1.8957     val_loss 1.6811 train_acc 0.4499 val_acc 0.5307 val_acc_top3 0.5307\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  27%|██▋       | 4/15 [01:05<02:59, 16.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 004 train_loss: 1.6148     val_loss 1.6598 train_acc 0.5148 val_acc 0.4916 val_acc_top3 0.4916\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  33%|███▎      | 5/15 [01:22<02:44, 16.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 005 train_loss: 1.3855     val_loss 1.4709 train_acc 0.5907 val_acc 0.5642 val_acc_top3 0.5642\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  40%|████      | 6/15 [01:38<02:27, 16.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 006 train_loss: 1.2204     val_loss 1.6031 train_acc 0.6164 val_acc 0.5698 val_acc_top3 0.5698\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  47%|████▋     | 7/15 [01:54<02:10, 16.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 007 train_loss: 1.1028     val_loss 1.4626 train_acc 0.6567 val_acc 0.5754 val_acc_top3 0.5754\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  53%|█████▎    | 8/15 [02:11<01:54, 16.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 008 train_loss: 0.9821     val_loss 1.3703 train_acc 0.6920 val_acc 0.6034 val_acc_top3 0.6034\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  60%|██████    | 9/15 [02:27<01:38, 16.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 009 train_loss: 0.8377     val_loss 1.3300 train_acc 0.7328 val_acc 0.6034 val_acc_top3 0.6034\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  67%|██████▋   | 10/15 [02:43<01:21, 16.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 010 train_loss: 0.7695     val_loss 1.3742 train_acc 0.7599 val_acc 0.6145 val_acc_top3 0.6145\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  73%|███████▎  | 11/15 [02:59<01:04, 16.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 011 train_loss: 0.6754     val_loss 1.4123 train_acc 0.7810 val_acc 0.6089 val_acc_top3 0.6089\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  80%|████████  | 12/15 [03:17<00:49, 16.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 012 train_loss: 0.6102     val_loss 1.4221 train_acc 0.8018 val_acc 0.5698 val_acc_top3 0.5698\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  87%|████████▋ | 13/15 [03:33<00:32, 16.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 013 train_loss: 0.5983     val_loss 1.4243 train_acc 0.8176 val_acc 0.6089 val_acc_top3 0.6089\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  93%|█████████▎| 14/15 [03:49<00:16, 16.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 014 train_loss: 0.5316     val_loss 1.4270 train_acc 0.8341 val_acc 0.6313 val_acc_top3 0.6313\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch: 100%|██████████| 15/15 [04:06<00:00, 16.43s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 015 train_loss: 0.4904     val_loss 1.4509 train_acc 0.8433 val_acc 0.6425 val_acc_top3 0.6425\n",
            "result: 0.6424581005586593\n",
            "learning_rate= 0.002 kernel_size= 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:   7%|▋         | 1/15 [00:16<03:51, 16.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 001 train_loss: 3.1914     val_loss 2.2816 train_acc 0.1553 val_acc 0.4078 val_acc_top3 0.4078\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  13%|█▎        | 2/15 [00:33<03:36, 16.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 002 train_loss: 2.3247     val_loss 1.9123 train_acc 0.3417 val_acc 0.4190 val_acc_top3 0.4190\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  20%|██        | 3/15 [00:50<03:23, 16.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 003 train_loss: 1.8974     val_loss 1.6602 train_acc 0.4426 val_acc 0.4637 val_acc_top3 0.4637\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  27%|██▋       | 4/15 [01:07<03:04, 16.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 004 train_loss: 1.5875     val_loss 1.6112 train_acc 0.5277 val_acc 0.5140 val_acc_top3 0.5140\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  33%|███▎      | 5/15 [01:23<02:47, 16.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 005 train_loss: 1.3713     val_loss 1.4907 train_acc 0.5858 val_acc 0.5196 val_acc_top3 0.5196\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  40%|████      | 6/15 [01:41<02:32, 16.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 006 train_loss: 1.1879     val_loss 1.3896 train_acc 0.6306 val_acc 0.5698 val_acc_top3 0.5698\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  47%|████▋     | 7/15 [01:58<02:16, 17.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 007 train_loss: 1.0289     val_loss 1.4586 train_acc 0.6817 val_acc 0.5810 val_acc_top3 0.5810\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  53%|█████▎    | 8/15 [02:15<01:59, 17.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 008 train_loss: 0.9434     val_loss 1.3010 train_acc 0.7048 val_acc 0.5810 val_acc_top3 0.5810\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  60%|██████    | 9/15 [02:32<01:42, 17.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 009 train_loss: 0.8282     val_loss 1.3840 train_acc 0.7375 val_acc 0.5754 val_acc_top3 0.5754\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  67%|██████▋   | 10/15 [02:49<01:24, 16.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 010 train_loss: 0.7537     val_loss 1.4400 train_acc 0.7672 val_acc 0.5419 val_acc_top3 0.5419\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  73%|███████▎  | 11/15 [03:06<01:07, 16.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 011 train_loss: 0.6606     val_loss 1.3324 train_acc 0.7902 val_acc 0.5978 val_acc_top3 0.5978\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  80%|████████  | 12/15 [03:22<00:50, 16.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 012 train_loss: 0.5739     val_loss 1.3645 train_acc 0.8203 val_acc 0.5698 val_acc_top3 0.5698\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  87%|████████▋ | 13/15 [03:39<00:33, 16.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 013 train_loss: 0.5228     val_loss 1.4285 train_acc 0.8298 val_acc 0.5978 val_acc_top3 0.5978\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  93%|█████████▎| 14/15 [03:57<00:17, 17.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 014 train_loss: 0.4996     val_loss 1.4464 train_acc 0.8377 val_acc 0.5978 val_acc_top3 0.5978\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch: 100%|██████████| 15/15 [04:13<00:00, 16.91s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 015 train_loss: 0.4451     val_loss 1.3862 train_acc 0.8592 val_acc 0.5866 val_acc_top3 0.5866\n",
            "result: 0.5865921787709497\n",
            "learning_rate= 0.004 kernel_size= 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:   7%|▋         | 1/15 [00:14<03:27, 14.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 001 train_loss: 3.4846     val_loss 2.3623 train_acc 0.1445 val_acc 0.3073 val_acc_top3 0.3073\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  13%|█▎        | 2/15 [00:30<03:18, 15.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 002 train_loss: 2.4597     val_loss 2.0108 train_acc 0.3057 val_acc 0.4860 val_acc_top3 0.4860\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  20%|██        | 3/15 [00:45<03:03, 15.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 003 train_loss: 2.0274     val_loss 1.6804 train_acc 0.4142 val_acc 0.5587 val_acc_top3 0.5587\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  27%|██▋       | 4/15 [01:00<02:46, 15.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 004 train_loss: 1.6901     val_loss 1.6552 train_acc 0.5007 val_acc 0.4860 val_acc_top3 0.4860\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  33%|███▎      | 5/15 [01:14<02:27, 14.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 005 train_loss: 1.5001     val_loss 1.5083 train_acc 0.5478 val_acc 0.5531 val_acc_top3 0.5531\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  40%|████      | 6/15 [01:28<02:10, 14.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 006 train_loss: 1.3139     val_loss 1.4359 train_acc 0.6036 val_acc 0.6034 val_acc_top3 0.6034\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  47%|████▋     | 7/15 [01:42<01:54, 14.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 007 train_loss: 1.1521     val_loss 1.4066 train_acc 0.6428 val_acc 0.6034 val_acc_top3 0.6034\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  53%|█████▎    | 8/15 [01:56<01:39, 14.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 008 train_loss: 1.0200     val_loss 1.5440 train_acc 0.6761 val_acc 0.5922 val_acc_top3 0.5922\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  60%|██████    | 9/15 [02:10<01:24, 14.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 009 train_loss: 0.9126     val_loss 1.4250 train_acc 0.7134 val_acc 0.6369 val_acc_top3 0.6369\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  67%|██████▋   | 10/15 [02:24<01:10, 14.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 010 train_loss: 0.7873     val_loss 1.3832 train_acc 0.7464 val_acc 0.6369 val_acc_top3 0.6369\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  73%|███████▎  | 11/15 [02:38<00:56, 14.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 011 train_loss: 0.7246     val_loss 1.4375 train_acc 0.7704 val_acc 0.5978 val_acc_top3 0.5978\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  80%|████████  | 12/15 [02:52<00:42, 14.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 012 train_loss: 0.6852     val_loss 1.3568 train_acc 0.7823 val_acc 0.6089 val_acc_top3 0.6089\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  87%|████████▋ | 13/15 [03:06<00:28, 14.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 013 train_loss: 0.5778     val_loss 1.4590 train_acc 0.8130 val_acc 0.5922 val_acc_top3 0.5922\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  93%|█████████▎| 14/15 [03:21<00:14, 14.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 014 train_loss: 0.5213     val_loss 1.4803 train_acc 0.8328 val_acc 0.5698 val_acc_top3 0.5698\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch: 100%|██████████| 15/15 [03:35<00:00, 14.35s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 015 train_loss: 0.4910     val_loss 1.4852 train_acc 0.8400 val_acc 0.6145 val_acc_top3 0.6145\n",
            "result: 0.6145251396648045\n",
            "learning_rate= 0.004 kernel_size= 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:   7%|▋         | 1/15 [00:15<03:33, 15.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 001 train_loss: 3.5091     val_loss 2.5180 train_acc 0.1280 val_acc 0.2793 val_acc_top3 0.2793\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  13%|█▎        | 2/15 [00:30<03:21, 15.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 002 train_loss: 2.6347     val_loss 1.9563 train_acc 0.2794 val_acc 0.4246 val_acc_top3 0.4246\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  20%|██        | 3/15 [00:46<03:06, 15.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 003 train_loss: 2.1251     val_loss 1.8014 train_acc 0.3809 val_acc 0.4749 val_acc_top3 0.4749\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  27%|██▋       | 4/15 [01:01<02:50, 15.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 004 train_loss: 1.8129     val_loss 1.7848 train_acc 0.4710 val_acc 0.4916 val_acc_top3 0.4916\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  33%|███▎      | 5/15 [01:17<02:33, 15.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 005 train_loss: 1.6045     val_loss 1.5163 train_acc 0.5152 val_acc 0.5307 val_acc_top3 0.5307\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  40%|████      | 6/15 [01:32<02:17, 15.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 006 train_loss: 1.3548     val_loss 1.4451 train_acc 0.5792 val_acc 0.5419 val_acc_top3 0.5419\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  47%|████▋     | 7/15 [01:48<02:04, 15.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 007 train_loss: 1.2226     val_loss 1.5340 train_acc 0.6243 val_acc 0.5307 val_acc_top3 0.5307\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  53%|█████▎    | 8/15 [02:03<01:47, 15.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 008 train_loss: 1.0616     val_loss 1.4815 train_acc 0.6669 val_acc 0.5363 val_acc_top3 0.5363\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  60%|██████    | 9/15 [02:18<01:32, 15.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 009 train_loss: 0.9836     val_loss 1.4508 train_acc 0.6814 val_acc 0.5642 val_acc_top3 0.5642\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  67%|██████▋   | 10/15 [02:34<01:17, 15.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 010 train_loss: 0.8286     val_loss 1.6848 train_acc 0.7315 val_acc 0.5307 val_acc_top3 0.5307\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  73%|███████▎  | 11/15 [02:50<01:02, 15.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 011 train_loss: 0.7849     val_loss 1.4867 train_acc 0.7431 val_acc 0.5698 val_acc_top3 0.5698\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  80%|████████  | 12/15 [03:05<00:46, 15.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 012 train_loss: 0.7130     val_loss 1.5081 train_acc 0.7652 val_acc 0.5810 val_acc_top3 0.5810\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  87%|████████▋ | 13/15 [03:21<00:30, 15.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 013 train_loss: 0.6206     val_loss 1.4955 train_acc 0.7955 val_acc 0.5866 val_acc_top3 0.5866\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  93%|█████████▎| 14/15 [03:36<00:15, 15.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 014 train_loss: 0.5801     val_loss 1.4178 train_acc 0.8160 val_acc 0.5810 val_acc_top3 0.5810\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch: 100%|██████████| 15/15 [03:51<00:00, 15.46s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 015 train_loss: 0.4916     val_loss 1.5073 train_acc 0.8364 val_acc 0.5866 val_acc_top3 0.5866\n",
            "result: 0.5865921787709497\n",
            "learning_rate= 0.004 kernel_size= 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:   7%|▋         | 1/15 [00:16<03:50, 16.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 001 train_loss: 3.5294     val_loss 2.5027 train_acc 0.1237 val_acc 0.2905 val_acc_top3 0.2905\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  13%|█▎        | 2/15 [00:32<03:28, 16.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 002 train_loss: 2.6434     val_loss 1.9908 train_acc 0.2734 val_acc 0.3911 val_acc_top3 0.3911\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  20%|██        | 3/15 [00:48<03:11, 15.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 003 train_loss: 2.1362     val_loss 1.6976 train_acc 0.3757 val_acc 0.5028 val_acc_top3 0.5028\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  27%|██▋       | 4/15 [01:04<02:57, 16.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 004 train_loss: 1.8534     val_loss 1.6690 train_acc 0.4522 val_acc 0.4749 val_acc_top3 0.4749\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  33%|███▎      | 5/15 [01:21<02:43, 16.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 005 train_loss: 1.6217     val_loss 1.4919 train_acc 0.5228 val_acc 0.5475 val_acc_top3 0.5475\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  40%|████      | 6/15 [01:37<02:25, 16.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 006 train_loss: 1.4570     val_loss 1.4205 train_acc 0.5544 val_acc 0.5196 val_acc_top3 0.5196\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  47%|████▋     | 7/15 [01:53<02:08, 16.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 007 train_loss: 1.2916     val_loss 1.4937 train_acc 0.5943 val_acc 0.5419 val_acc_top3 0.5419\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  53%|█████▎    | 8/15 [02:09<01:53, 16.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 008 train_loss: 1.1325     val_loss 1.4777 train_acc 0.6461 val_acc 0.5419 val_acc_top3 0.5419\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  60%|██████    | 9/15 [02:25<01:36, 16.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 009 train_loss: 1.0205     val_loss 1.3841 train_acc 0.6702 val_acc 0.5531 val_acc_top3 0.5531\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  67%|██████▋   | 10/15 [02:41<01:21, 16.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 010 train_loss: 0.8931     val_loss 1.3560 train_acc 0.7206 val_acc 0.5754 val_acc_top3 0.5754\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  73%|███████▎  | 11/15 [02:59<01:06, 16.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 011 train_loss: 0.8632     val_loss 1.3697 train_acc 0.7223 val_acc 0.5866 val_acc_top3 0.5866\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  80%|████████  | 12/15 [03:16<00:49, 16.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 012 train_loss: 0.7398     val_loss 1.3183 train_acc 0.7447 val_acc 0.5922 val_acc_top3 0.5922\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  87%|████████▋ | 13/15 [03:32<00:33, 16.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 013 train_loss: 0.6786     val_loss 1.3255 train_acc 0.7856 val_acc 0.6089 val_acc_top3 0.6089\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  93%|█████████▎| 14/15 [03:50<00:16, 16.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 014 train_loss: 0.5907     val_loss 1.3734 train_acc 0.8044 val_acc 0.5698 val_acc_top3 0.5698\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch: 100%|██████████| 15/15 [04:07<00:00, 16.50s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 015 train_loss: 0.5806     val_loss 1.4714 train_acc 0.8110 val_acc 0.5642 val_acc_top3 0.5642\n",
            "result: 0.5642458100558659\n",
            "learning_rate= 0.006 kernel_size= 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:   7%|▋         | 1/15 [00:14<03:25, 14.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 001 train_loss: 3.8386     val_loss 2.5113 train_acc 0.1168 val_acc 0.2849 val_acc_top3 0.2849\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  13%|█▎        | 2/15 [00:29<03:10, 14.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 002 train_loss: 2.6361     val_loss 2.0454 train_acc 0.2925 val_acc 0.3911 val_acc_top3 0.3911\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  20%|██        | 3/15 [00:44<02:59, 14.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 003 train_loss: 2.1544     val_loss 1.7637 train_acc 0.3793 val_acc 0.4413 val_acc_top3 0.4413\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  27%|██▋       | 4/15 [00:59<02:43, 14.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 004 train_loss: 1.8941     val_loss 1.6760 train_acc 0.4410 val_acc 0.4972 val_acc_top3 0.4972\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  33%|███▎      | 5/15 [01:13<02:27, 14.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 005 train_loss: 1.6319     val_loss 1.7606 train_acc 0.5053 val_acc 0.4804 val_acc_top3 0.4804\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  40%|████      | 6/15 [01:28<02:12, 14.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 006 train_loss: 1.4247     val_loss 1.6457 train_acc 0.5663 val_acc 0.5140 val_acc_top3 0.5140\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  47%|████▋     | 7/15 [01:43<01:57, 14.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 007 train_loss: 1.3373     val_loss 1.5391 train_acc 0.5983 val_acc 0.4972 val_acc_top3 0.4972\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  53%|█████▎    | 8/15 [01:58<01:43, 14.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 008 train_loss: 1.1608     val_loss 1.5233 train_acc 0.6339 val_acc 0.5531 val_acc_top3 0.5531\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  60%|██████    | 9/15 [02:13<01:29, 14.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 009 train_loss: 1.0722     val_loss 1.4737 train_acc 0.6689 val_acc 0.5251 val_acc_top3 0.5251\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  67%|██████▋   | 10/15 [02:27<01:13, 14.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 010 train_loss: 0.9325     val_loss 1.5956 train_acc 0.7038 val_acc 0.5587 val_acc_top3 0.5587\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  73%|███████▎  | 11/15 [02:42<00:58, 14.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 011 train_loss: 0.8117     val_loss 1.6906 train_acc 0.7385 val_acc 0.5419 val_acc_top3 0.5419\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  80%|████████  | 12/15 [02:58<00:44, 14.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 012 train_loss: 0.7524     val_loss 1.7302 train_acc 0.7576 val_acc 0.5531 val_acc_top3 0.5531\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  87%|████████▋ | 13/15 [03:12<00:29, 14.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 013 train_loss: 0.7160     val_loss 1.4994 train_acc 0.7770 val_acc 0.5866 val_acc_top3 0.5866\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  93%|█████████▎| 14/15 [03:27<00:14, 14.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 014 train_loss: 0.6086     val_loss 1.5933 train_acc 0.7982 val_acc 0.5642 val_acc_top3 0.5642\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch: 100%|██████████| 15/15 [03:42<00:00, 14.84s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 015 train_loss: 0.5629     val_loss 1.7479 train_acc 0.8140 val_acc 0.5810 val_acc_top3 0.5810\n",
            "result: 0.5810055865921788\n",
            "learning_rate= 0.006 kernel_size= 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:   7%|▋         | 1/15 [00:16<03:45, 16.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 001 train_loss: 3.9217     val_loss 2.6525 train_acc 0.1052 val_acc 0.2626 val_acc_top3 0.2626\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  13%|█▎        | 2/15 [00:32<03:28, 16.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 002 train_loss: 2.7607     val_loss 2.1487 train_acc 0.2589 val_acc 0.3743 val_acc_top3 0.3743\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  20%|██        | 3/15 [00:48<03:15, 16.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 003 train_loss: 2.2964     val_loss 1.9234 train_acc 0.3387 val_acc 0.4302 val_acc_top3 0.4302\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  27%|██▋       | 4/15 [01:04<02:58, 16.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 004 train_loss: 2.0525     val_loss 1.7001 train_acc 0.3997 val_acc 0.4860 val_acc_top3 0.4860\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  33%|███▎      | 5/15 [01:20<02:41, 16.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 005 train_loss: 1.7898     val_loss 1.6153 train_acc 0.4578 val_acc 0.5642 val_acc_top3 0.5642\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  40%|████      | 6/15 [01:37<02:26, 16.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 006 train_loss: 1.6135     val_loss 1.5566 train_acc 0.5158 val_acc 0.5642 val_acc_top3 0.5642\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  47%|████▋     | 7/15 [01:54<02:11, 16.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 007 train_loss: 1.4282     val_loss 1.4508 train_acc 0.5703 val_acc 0.5531 val_acc_top3 0.5531\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  53%|█████▎    | 8/15 [02:10<01:54, 16.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 008 train_loss: 1.2564     val_loss 1.5182 train_acc 0.6171 val_acc 0.5419 val_acc_top3 0.5419\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  60%|██████    | 9/15 [02:26<01:37, 16.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 009 train_loss: 1.1422     val_loss 1.4516 train_acc 0.6435 val_acc 0.5587 val_acc_top3 0.5587\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  67%|██████▋   | 10/15 [02:42<01:21, 16.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 010 train_loss: 1.0351     val_loss 1.3615 train_acc 0.6699 val_acc 0.5866 val_acc_top3 0.5866\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  73%|███████▎  | 11/15 [02:58<01:04, 16.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 011 train_loss: 0.9395     val_loss 1.3672 train_acc 0.6976 val_acc 0.5810 val_acc_top3 0.5810\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  80%|████████  | 12/15 [03:14<00:48, 16.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 012 train_loss: 0.8856     val_loss 1.3318 train_acc 0.7147 val_acc 0.6257 val_acc_top3 0.6257\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  87%|████████▋ | 13/15 [03:31<00:32, 16.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 013 train_loss: 0.7707     val_loss 1.4561 train_acc 0.7427 val_acc 0.6089 val_acc_top3 0.6089\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  93%|█████████▎| 14/15 [03:47<00:16, 16.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 014 train_loss: 0.6925     val_loss 1.5225 train_acc 0.7675 val_acc 0.5698 val_acc_top3 0.5698\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch: 100%|██████████| 15/15 [04:03<00:00, 16.21s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 015 train_loss: 0.6364     val_loss 1.4563 train_acc 0.8011 val_acc 0.5978 val_acc_top3 0.5978\n",
            "result: 0.5977653631284916\n",
            "learning_rate= 0.006 kernel_size= 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:   7%|▋         | 1/15 [00:16<03:46, 16.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 001 train_loss: 4.0873     val_loss 2.8000 train_acc 0.0960 val_acc 0.1620 val_acc_top3 0.1620\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  13%|█▎        | 2/15 [00:33<03:38, 16.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 002 train_loss: 2.9814     val_loss 2.6364 train_acc 0.2042 val_acc 0.2905 val_acc_top3 0.2905\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  20%|██        | 3/15 [00:49<03:16, 16.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 003 train_loss: 2.5988     val_loss 2.0411 train_acc 0.2813 val_acc 0.4022 val_acc_top3 0.4022\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  27%|██▋       | 4/15 [01:05<02:58, 16.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 004 train_loss: 2.3212     val_loss 1.8672 train_acc 0.3341 val_acc 0.4246 val_acc_top3 0.4246\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  33%|███▎      | 5/15 [01:21<02:42, 16.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 005 train_loss: 2.0625     val_loss 1.8822 train_acc 0.3928 val_acc 0.4469 val_acc_top3 0.4469\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  40%|████      | 6/15 [01:37<02:26, 16.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 006 train_loss: 1.9065     val_loss 1.8340 train_acc 0.4377 val_acc 0.4469 val_acc_top3 0.4469\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  47%|████▋     | 7/15 [01:53<02:08, 16.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 007 train_loss: 1.6794     val_loss 1.6655 train_acc 0.4924 val_acc 0.4916 val_acc_top3 0.4916\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  53%|█████▎    | 8/15 [02:09<01:52, 16.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 008 train_loss: 1.5549     val_loss 1.5933 train_acc 0.5363 val_acc 0.5084 val_acc_top3 0.5084\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  60%|██████    | 9/15 [02:25<01:36, 16.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 009 train_loss: 1.3908     val_loss 1.5784 train_acc 0.5775 val_acc 0.5642 val_acc_top3 0.5642\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  67%|██████▋   | 10/15 [02:41<01:19, 16.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 010 train_loss: 1.3443     val_loss 1.4861 train_acc 0.5795 val_acc 0.5642 val_acc_top3 0.5642\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  73%|███████▎  | 11/15 [02:57<01:03, 15.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 011 train_loss: 1.2099     val_loss 1.4948 train_acc 0.6214 val_acc 0.5196 val_acc_top3 0.5196\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  80%|████████  | 12/15 [03:13<00:47, 15.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 012 train_loss: 1.0785     val_loss 1.4819 train_acc 0.6547 val_acc 0.5251 val_acc_top3 0.5251\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  87%|████████▋ | 13/15 [03:30<00:32, 16.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 013 train_loss: 0.9774     val_loss 1.4834 train_acc 0.6887 val_acc 0.5587 val_acc_top3 0.5587\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  93%|█████████▎| 14/15 [03:46<00:16, 16.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 014 train_loss: 0.9046     val_loss 1.5004 train_acc 0.7075 val_acc 0.5587 val_acc_top3 0.5587\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch: 100%|██████████| 15/15 [04:02<00:00, 16.14s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 015 train_loss: 0.8505     val_loss 1.5015 train_acc 0.7239 val_acc 0.5698 val_acc_top3 0.5698\n",
            "result: 0.5698324022346369\n",
            "learning_rate= 0.01 kernel_size= 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:   7%|▋         | 1/15 [00:13<03:13, 13.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 001 train_loss: 4.3028     val_loss 2.9547 train_acc 0.1085 val_acc 0.2123 val_acc_top3 0.2123\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  13%|█▎        | 2/15 [00:27<02:58, 13.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 002 train_loss: 2.9477     val_loss 2.5110 train_acc 0.2051 val_acc 0.2961 val_acc_top3 0.2961\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  20%|██        | 3/15 [00:41<02:46, 13.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 003 train_loss: 2.6619     val_loss 2.3743 train_acc 0.2536 val_acc 0.2570 val_acc_top3 0.2570\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  27%|██▋       | 4/15 [00:55<02:34, 14.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 004 train_loss: 2.4221     val_loss 2.3852 train_acc 0.3163 val_acc 0.3464 val_acc_top3 0.3464\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  33%|███▎      | 5/15 [01:09<02:20, 14.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 005 train_loss: 2.2121     val_loss 1.7662 train_acc 0.3654 val_acc 0.4693 val_acc_top3 0.4693\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  40%|████      | 6/15 [01:23<02:05, 13.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 006 train_loss: 1.9666     val_loss 1.7164 train_acc 0.4261 val_acc 0.4525 val_acc_top3 0.4525\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  47%|████▋     | 7/15 [01:37<01:51, 13.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 007 train_loss: 1.7547     val_loss 1.6693 train_acc 0.4687 val_acc 0.5084 val_acc_top3 0.5084\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  53%|█████▎    | 8/15 [01:51<01:37, 13.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 008 train_loss: 1.5230     val_loss 1.5376 train_acc 0.5251 val_acc 0.5531 val_acc_top3 0.5531\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  60%|██████    | 9/15 [02:06<01:25, 14.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 009 train_loss: 1.4146     val_loss 1.4788 train_acc 0.5607 val_acc 0.5419 val_acc_top3 0.5419\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  67%|██████▋   | 10/15 [02:20<01:10, 14.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 010 train_loss: 1.3106     val_loss 1.6053 train_acc 0.5930 val_acc 0.5084 val_acc_top3 0.5084\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  73%|███████▎  | 11/15 [02:33<00:55, 13.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 011 train_loss: 1.1889     val_loss 1.5895 train_acc 0.6369 val_acc 0.5419 val_acc_top3 0.5419\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  80%|████████  | 12/15 [02:47<00:41, 13.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 012 train_loss: 1.0461     val_loss 1.6158 train_acc 0.6609 val_acc 0.5642 val_acc_top3 0.5642\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  87%|████████▋ | 13/15 [03:01<00:28, 14.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 013 train_loss: 0.9806     val_loss 1.5516 train_acc 0.6939 val_acc 0.5363 val_acc_top3 0.5363\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  93%|█████████▎| 14/15 [03:16<00:14, 14.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 014 train_loss: 0.8624     val_loss 1.5275 train_acc 0.7246 val_acc 0.5419 val_acc_top3 0.5419\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch: 100%|██████████| 15/15 [03:30<00:00, 14.02s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 015 train_loss: 0.8784     val_loss 1.5936 train_acc 0.7134 val_acc 0.5587 val_acc_top3 0.5587\n",
            "result: 0.5586592178770949\n",
            "learning_rate= 0.01 kernel_size= 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:   7%|▋         | 1/15 [00:15<03:32, 15.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 001 train_loss: 4.7282     val_loss 2.8640 train_acc 0.1013 val_acc 0.1788 val_acc_top3 0.1788\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  13%|█▎        | 2/15 [00:30<03:19, 15.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 002 train_loss: 3.0276     val_loss 2.4604 train_acc 0.1854 val_acc 0.2961 val_acc_top3 0.2961\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  20%|██        | 3/15 [00:45<03:03, 15.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 003 train_loss: 2.6755     val_loss 2.1417 train_acc 0.2546 val_acc 0.4022 val_acc_top3 0.4022\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  27%|██▋       | 4/15 [01:01<02:50, 15.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 004 train_loss: 2.4110     val_loss 1.8889 train_acc 0.3051 val_acc 0.4190 val_acc_top3 0.4190\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  33%|███▎      | 5/15 [01:18<02:38, 15.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 005 train_loss: 2.1480     val_loss 1.8421 train_acc 0.3763 val_acc 0.4190 val_acc_top3 0.4190\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  40%|████      | 6/15 [01:34<02:23, 15.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 006 train_loss: 1.8938     val_loss 1.6288 train_acc 0.4426 val_acc 0.5140 val_acc_top3 0.5140\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  47%|████▋     | 7/15 [01:50<02:08, 16.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 007 train_loss: 1.7180     val_loss 1.6049 train_acc 0.4796 val_acc 0.4804 val_acc_top3 0.4804\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  53%|█████▎    | 8/15 [02:06<01:52, 16.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 008 train_loss: 1.5677     val_loss 1.5631 train_acc 0.5162 val_acc 0.5196 val_acc_top3 0.5196\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  60%|██████    | 9/15 [02:22<01:36, 16.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 009 train_loss: 1.4168     val_loss 1.4619 train_acc 0.5594 val_acc 0.5587 val_acc_top3 0.5587\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  67%|██████▋   | 10/15 [02:38<01:20, 16.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 010 train_loss: 1.3330     val_loss 1.4158 train_acc 0.5963 val_acc 0.5531 val_acc_top3 0.5531\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  73%|███████▎  | 11/15 [02:55<01:05, 16.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 011 train_loss: 1.1305     val_loss 1.4650 train_acc 0.6425 val_acc 0.5810 val_acc_top3 0.5810\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  80%|████████  | 12/15 [03:11<00:48, 16.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 012 train_loss: 1.0527     val_loss 1.4151 train_acc 0.6748 val_acc 0.5810 val_acc_top3 0.5810\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  87%|████████▋ | 13/15 [03:27<00:32, 16.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 013 train_loss: 0.9947     val_loss 1.5586 train_acc 0.6920 val_acc 0.5978 val_acc_top3 0.5978\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  93%|█████████▎| 14/15 [03:44<00:16, 16.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 014 train_loss: 0.9172     val_loss 1.5296 train_acc 0.7094 val_acc 0.5810 val_acc_top3 0.5810\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch: 100%|██████████| 15/15 [04:01<00:00, 16.08s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 015 train_loss: 0.8290     val_loss 1.5459 train_acc 0.7246 val_acc 0.5810 val_acc_top3 0.5810\n",
            "result: 0.5810055865921788\n",
            "learning_rate= 0.01 kernel_size= 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:   7%|▋         | 1/15 [00:16<03:47, 16.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 001 train_loss: 5.0983     val_loss 3.2898 train_acc 0.0782 val_acc 0.1285 val_acc_top3 0.1285\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  13%|█▎        | 2/15 [00:33<03:37, 16.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 002 train_loss: 3.3148     val_loss 2.9514 train_acc 0.1092 val_acc 0.1788 val_acc_top3 0.1788\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  20%|██        | 3/15 [00:50<03:21, 16.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 003 train_loss: 3.1483     val_loss 2.7783 train_acc 0.1418 val_acc 0.2346 val_acc_top3 0.2346\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  27%|██▋       | 4/15 [01:06<03:03, 16.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 004 train_loss: 2.9791     val_loss 2.5074 train_acc 0.1827 val_acc 0.2682 val_acc_top3 0.2682\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  33%|███▎      | 5/15 [01:23<02:48, 16.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 005 train_loss: 2.8149     val_loss 2.3317 train_acc 0.2091 val_acc 0.3073 val_acc_top3 0.3073\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  40%|████      | 6/15 [01:40<02:31, 16.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 006 train_loss: 2.7034     val_loss 2.3100 train_acc 0.2177 val_acc 0.3073 val_acc_top3 0.3073\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  47%|████▋     | 7/15 [01:57<02:13, 16.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 007 train_loss: 2.5549     val_loss 2.1265 train_acc 0.2553 val_acc 0.3687 val_acc_top3 0.3687\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  53%|█████▎    | 8/15 [02:14<01:57, 16.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 008 train_loss: 2.3503     val_loss 2.0199 train_acc 0.3071 val_acc 0.3743 val_acc_top3 0.3743\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  60%|██████    | 9/15 [02:30<01:40, 16.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 009 train_loss: 2.1279     val_loss 1.9047 train_acc 0.3592 val_acc 0.3799 val_acc_top3 0.3799\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  67%|██████▋   | 10/15 [02:48<01:24, 16.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 010 train_loss: 2.0409     val_loss 1.8941 train_acc 0.3813 val_acc 0.4190 val_acc_top3 0.4190\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  73%|███████▎  | 11/15 [03:05<01:08, 17.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 011 train_loss: 1.8885     val_loss 1.7350 train_acc 0.4456 val_acc 0.4693 val_acc_top3 0.4693\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  80%|████████  | 12/15 [03:21<00:50, 16.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 012 train_loss: 1.7180     val_loss 1.7076 train_acc 0.4759 val_acc 0.4916 val_acc_top3 0.4916\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  87%|████████▋ | 13/15 [03:38<00:33, 16.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 013 train_loss: 1.6160     val_loss 1.6914 train_acc 0.5003 val_acc 0.5475 val_acc_top3 0.5475\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  93%|█████████▎| 14/15 [03:55<00:16, 16.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 014 train_loss: 1.5093     val_loss 1.6840 train_acc 0.5204 val_acc 0.5419 val_acc_top3 0.5419\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch: 100%|██████████| 15/15 [04:12<00:00, 16.80s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 015 train_loss: 1.4100     val_loss 1.6853 train_acc 0.5637 val_acc 0.5587 val_acc_top3 0.5587\n",
            "result: 0.5586592178770949\n",
            "learning_rate= 0.05 kernel_size= 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:   7%|▋         | 1/15 [00:14<03:24, 14.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 001 train_loss: 12.0355     val_loss 3.7259 train_acc 0.0336 val_acc 0.0615 val_acc_top3 0.0615\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  13%|█▎        | 2/15 [00:29<03:10, 14.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 002 train_loss: 3.9977     val_loss 3.5210 train_acc 0.0327 val_acc 0.0838 val_acc_top3 0.0838\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  20%|██        | 3/15 [00:44<02:59, 14.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 003 train_loss: 3.6025     val_loss 3.4896 train_acc 0.0409 val_acc 0.0670 val_acc_top3 0.0670\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  27%|██▋       | 4/15 [00:59<02:43, 14.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 004 train_loss: 3.5545     val_loss 3.4609 train_acc 0.0574 val_acc 0.0950 val_acc_top3 0.0950\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  33%|███▎      | 5/15 [01:14<02:29, 14.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 005 train_loss: 3.4934     val_loss 3.4280 train_acc 0.0653 val_acc 0.0615 val_acc_top3 0.0615\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  40%|████      | 6/15 [01:29<02:13, 14.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 006 train_loss: 3.4561     val_loss 3.3267 train_acc 0.0709 val_acc 0.0838 val_acc_top3 0.0838\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  47%|████▋     | 7/15 [01:43<01:58, 14.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 007 train_loss: 3.4750     val_loss 3.3078 train_acc 0.0716 val_acc 0.1006 val_acc_top3 0.1006\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  53%|█████▎    | 8/15 [01:58<01:43, 14.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 008 train_loss: 3.4637     val_loss 3.3990 train_acc 0.0683 val_acc 0.1006 val_acc_top3 0.1006\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  60%|██████    | 9/15 [02:13<01:29, 14.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 009 train_loss: 3.4312     val_loss 3.2401 train_acc 0.0729 val_acc 0.1173 val_acc_top3 0.1173\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  67%|██████▋   | 10/15 [02:27<01:13, 14.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 010 train_loss: 3.3925     val_loss 3.0848 train_acc 0.0834 val_acc 0.1341 val_acc_top3 0.1341\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  73%|███████▎  | 11/15 [02:41<00:57, 14.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 011 train_loss: 3.3682     val_loss 3.1842 train_acc 0.0874 val_acc 0.1341 val_acc_top3 0.1341\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  80%|████████  | 12/15 [02:55<00:42, 14.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 012 train_loss: 3.3454     val_loss 3.1637 train_acc 0.0894 val_acc 0.1676 val_acc_top3 0.1676\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  87%|████████▋ | 13/15 [03:09<00:28, 14.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 013 train_loss: 3.3347     val_loss 3.1465 train_acc 0.0970 val_acc 0.1117 val_acc_top3 0.1117\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  93%|█████████▎| 14/15 [03:22<00:13, 13.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 014 train_loss: 3.4165     val_loss 3.1251 train_acc 0.0854 val_acc 0.1453 val_acc_top3 0.1453\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch: 100%|██████████| 15/15 [03:36<00:00, 14.45s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 015 train_loss: 3.2869     val_loss 3.0682 train_acc 0.1088 val_acc 0.1508 val_acc_top3 0.1508\n",
            "result: 0.15083798882681565\n",
            "learning_rate= 0.05 kernel_size= 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:   7%|▋         | 1/15 [00:17<04:03, 17.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 001 train_loss: 12.2931     val_loss 3.6013 train_acc 0.0406 val_acc 0.0670 val_acc_top3 0.0670\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  13%|█▎        | 2/15 [00:32<03:31, 16.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 002 train_loss: 3.9858     val_loss 3.4229 train_acc 0.0416 val_acc 0.0726 val_acc_top3 0.0726\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  20%|██        | 3/15 [00:48<03:13, 16.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 003 train_loss: 3.5663     val_loss 3.4777 train_acc 0.0554 val_acc 0.1117 val_acc_top3 0.1117\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  27%|██▋       | 4/15 [01:04<02:55, 15.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 004 train_loss: 3.5019     val_loss 3.4378 train_acc 0.0617 val_acc 0.0894 val_acc_top3 0.0894\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  33%|███▎      | 5/15 [01:20<02:41, 16.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 005 train_loss: 3.5070     val_loss 3.3962 train_acc 0.0584 val_acc 0.0726 val_acc_top3 0.0726\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  40%|████      | 6/15 [01:36<02:22, 15.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 006 train_loss: 3.4462     val_loss 3.3654 train_acc 0.0656 val_acc 0.0894 val_acc_top3 0.0894\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  47%|████▋     | 7/15 [01:52<02:06, 15.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 007 train_loss: 3.4710     val_loss 3.4203 train_acc 0.0653 val_acc 0.0838 val_acc_top3 0.0838\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  53%|█████▎    | 8/15 [02:07<01:50, 15.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 008 train_loss: 3.4657     val_loss 3.2603 train_acc 0.0693 val_acc 0.1173 val_acc_top3 0.1173\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  60%|██████    | 9/15 [02:24<01:36, 16.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 009 train_loss: 3.4173     val_loss 3.3122 train_acc 0.0805 val_acc 0.0894 val_acc_top3 0.0894\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  67%|██████▋   | 10/15 [02:40<01:19, 15.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 010 train_loss: 3.4145     val_loss 3.2629 train_acc 0.0805 val_acc 0.1173 val_acc_top3 0.1173\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  73%|███████▎  | 11/15 [02:56<01:04, 16.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 011 train_loss: 3.3600     val_loss 3.0675 train_acc 0.0966 val_acc 0.1620 val_acc_top3 0.1620\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  80%|████████  | 12/15 [03:12<00:47, 15.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 012 train_loss: 3.3613     val_loss 3.2382 train_acc 0.1092 val_acc 0.1006 val_acc_top3 0.1006\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  87%|████████▋ | 13/15 [03:28<00:32, 16.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 013 train_loss: 3.3415     val_loss 3.0653 train_acc 0.0953 val_acc 0.1229 val_acc_top3 0.1229\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  93%|█████████▎| 14/15 [03:44<00:15, 15.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 014 train_loss: 3.2646     val_loss 3.4209 train_acc 0.1220 val_acc 0.2123 val_acc_top3 0.2123\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch: 100%|██████████| 15/15 [03:59<00:00, 15.98s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 015 train_loss: 3.3262     val_loss 3.0183 train_acc 0.1075 val_acc 0.1899 val_acc_top3 0.1899\n",
            "result: 0.18994413407821228\n",
            "learning_rate= 0.05 kernel_size= 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:   7%|▋         | 1/15 [00:16<03:45, 16.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 001 train_loss: 11.6214     val_loss 3.7479 train_acc 0.0350 val_acc 0.0559 val_acc_top3 0.0559\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  13%|█▎        | 2/15 [00:32<03:33, 16.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 002 train_loss: 3.9330     val_loss 3.4969 train_acc 0.0290 val_acc 0.0391 val_acc_top3 0.0391\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  20%|██        | 3/15 [00:48<03:15, 16.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 003 train_loss: 3.5866     val_loss 3.4906 train_acc 0.0416 val_acc 0.0559 val_acc_top3 0.0559\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  27%|██▋       | 4/15 [01:04<02:58, 16.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 004 train_loss: 3.5823     val_loss 3.4606 train_acc 0.0554 val_acc 0.0615 val_acc_top3 0.0615\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  33%|███▎      | 5/15 [01:21<02:44, 16.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 005 train_loss: 3.5279     val_loss 3.4318 train_acc 0.0646 val_acc 0.0726 val_acc_top3 0.0726\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  40%|████      | 6/15 [01:39<02:30, 16.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 006 train_loss: 3.5341     val_loss 3.3531 train_acc 0.0547 val_acc 0.0670 val_acc_top3 0.0670\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  47%|████▋     | 7/15 [01:55<02:12, 16.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 007 train_loss: 3.4689     val_loss 3.3822 train_acc 0.0693 val_acc 0.0615 val_acc_top3 0.0615\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  53%|█████▎    | 8/15 [02:11<01:54, 16.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 008 train_loss: 3.4675     val_loss 3.3605 train_acc 0.0600 val_acc 0.1173 val_acc_top3 0.1173\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  60%|██████    | 9/15 [02:28<01:39, 16.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 009 train_loss: 3.4567     val_loss 3.3312 train_acc 0.0699 val_acc 0.0615 val_acc_top3 0.0615\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  67%|██████▋   | 10/15 [02:44<01:22, 16.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 010 train_loss: 3.4235     val_loss 3.3813 train_acc 0.0712 val_acc 0.0782 val_acc_top3 0.0782\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  73%|███████▎  | 11/15 [03:00<01:05, 16.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 011 train_loss: 3.4632     val_loss 3.2667 train_acc 0.0732 val_acc 0.1006 val_acc_top3 0.1006\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  80%|████████  | 12/15 [03:17<00:49, 16.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 012 train_loss: 3.4111     val_loss 3.3788 train_acc 0.0772 val_acc 0.0670 val_acc_top3 0.0670\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  87%|████████▋ | 13/15 [03:34<00:33, 16.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 013 train_loss: 3.4135     val_loss 3.2092 train_acc 0.0844 val_acc 0.0950 val_acc_top3 0.0950\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  93%|█████████▎| 14/15 [03:50<00:16, 16.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 014 train_loss: 3.3568     val_loss 3.3074 train_acc 0.0970 val_acc 0.0950 val_acc_top3 0.0950\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch: 100%|██████████| 15/15 [04:06<00:00, 16.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 015 train_loss: 3.3513     val_loss 3.2807 train_acc 0.0937 val_acc 0.1006 val_acc_top3 0.1006\n",
            "result: 0.1005586592178771\n",
            "(0.05, 7)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обучим модель с лучшими гиперпараметрами"
      ],
      "metadata": {
        "id": "q7jWSend_fUj"
      },
      "id": "q7jWSend_fUj"
    },
    {
      "cell_type": "code",
      "source": [
        "kernel_size = 5\n",
        "learning_rate = 0.002\n",
        "\n",
        "search_model = AdaptiveNetWork(kernel_size)\n",
        "search_model = search_model.to(DEVICE)\n",
        "history = train_search(train_dataset_multi, test_dataset_multi, search_model, 15, 64, learning_rate)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FGE0L6W5_THi",
        "outputId": "6c9b0f12-14d4-4796-e48b-5f464b4a177c"
      },
      "id": "FGE0L6W5_THi",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:   7%|▋         | 1/15 [00:16<03:45, 16.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 001 train_loss: 3.2563     val_loss 2.4551 train_acc 0.1382 val_acc 0.3266 val_acc_top3 0.3266\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  13%|█▎        | 2/15 [00:30<03:16, 15.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 002 train_loss: 2.4797     val_loss 2.0782 train_acc 0.2998 val_acc 0.4152 val_acc_top3 0.4152\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  20%|██        | 3/15 [00:44<02:57, 14.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 003 train_loss: 2.0242     val_loss 1.7811 train_acc 0.4132 val_acc 0.5054 val_acc_top3 0.5054\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  27%|██▋       | 4/15 [00:59<02:43, 14.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 004 train_loss: 1.7025     val_loss 1.7151 train_acc 0.4973 val_acc 0.5117 val_acc_top3 0.5117\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  33%|███▎      | 5/15 [01:14<02:27, 14.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 005 train_loss: 1.4643     val_loss 1.6640 train_acc 0.5627 val_acc 0.5505 val_acc_top3 0.5505\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  40%|████      | 6/15 [01:28<02:11, 14.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 006 train_loss: 1.2846     val_loss 1.6328 train_acc 0.6086 val_acc 0.5505 val_acc_top3 0.5505\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  47%|████▋     | 7/15 [01:43<01:57, 14.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 007 train_loss: 1.0555     val_loss 1.5439 train_acc 0.6830 val_acc 0.5816 val_acc_top3 0.5816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  53%|█████▎    | 8/15 [01:58<01:42, 14.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 008 train_loss: 0.9699     val_loss 1.5320 train_acc 0.7025 val_acc 0.5956 val_acc_top3 0.5956\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  60%|██████    | 9/15 [02:12<01:27, 14.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 009 train_loss: 0.8385     val_loss 1.4979 train_acc 0.7484 val_acc 0.5879 val_acc_top3 0.5879\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  67%|██████▋   | 10/15 [02:28<01:14, 14.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 010 train_loss: 0.7350     val_loss 1.5520 train_acc 0.7691 val_acc 0.6003 val_acc_top3 0.6003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  73%|███████▎  | 11/15 [02:42<00:59, 14.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 011 train_loss: 0.6708     val_loss 1.5639 train_acc 0.7850 val_acc 0.5770 val_acc_top3 0.5770\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  80%|████████  | 12/15 [02:57<00:44, 14.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 012 train_loss: 0.5713     val_loss 1.5402 train_acc 0.8189 val_acc 0.6081 val_acc_top3 0.6081\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  87%|████████▋ | 13/15 [03:12<00:29, 14.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 013 train_loss: 0.5331     val_loss 1.6272 train_acc 0.8357 val_acc 0.5785 val_acc_top3 0.5785\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  93%|█████████▎| 14/15 [03:27<00:15, 15.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 014 train_loss: 0.4646     val_loss 1.5338 train_acc 0.8524 val_acc 0.6112 val_acc_top3 0.6112\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch: 100%|██████████| 15/15 [03:42<00:00, 14.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 015 train_loss: 0.4380     val_loss 1.5847 train_acc 0.8563 val_acc 0.6128 val_acc_top3 0.6128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}